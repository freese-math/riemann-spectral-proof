{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP7S/wK1BKMb2HFj6CYKt9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Xp3jc9A4PjP","executionInfo":{"status":"ok","timestamp":1742160895323,"user_tz":-60,"elapsed":11778,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"d6022489-51b5-4ece-dfcf-8e89ead84cc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyWavelets\n","  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n","Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyWavelets\n","Successfully installed PyWavelets-1.8.0\n"]}],"source":["!pip install PyWavelets\n","import pywt"]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import gc\n","\n","# üîç Speicher freigeben\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# üîπ Nutze GPU, falls verf√ºgbar\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# üîπ Anzahl der Eigenwerte\n","N = 500  # Oder anpassen je nach Rechenleistung\n","\n","# üîπ Lade zuvor berechnete Nullstellen f√ºr H\n","zeta_zeros = torch.linspace(1, N, N, device=device)  # Hier ersetzen mit echten Daten\n","\n","# üîπ Definiere Hamilton-Operator H\n","H_diag = torch.diag(zeta_zeros)\n","H_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","H = H_diag + H_offdiag\n","\n","# üîπ Definiere T-Operator (Beta-Skala)\n","beta_values = torch.linspace(1, N, N, device=device)\n","T_diag = torch.diag(beta_values)\n","T_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","T = T_diag + T_offdiag\n","\n","# üîπ Eigenwerte und Eigenvektoren berechnen\n","H_eigenvalues, H_eigenvectors = torch.linalg.eigh(H)\n","T_eigenvalues, T_eigenvectors = torch.linalg.eigh(T)\n","\n","# üìå 1Ô∏è‚É£ Kommutator [H, T] berechnen\n","commutator_HT = H @ T - T @ H\n","norm_commutator = torch.norm(commutator_HT).item()\n","print(f\"üîç Norm des Kommutators [H, T]: {norm_commutator:.6f}\")\n","\n","# üìå 2Ô∏è‚É£ Eigenwerte des Kommutators berechnen\n","eigvals_commutator, _ = torch.linalg.eigh(commutator_HT)\n","print(f\"üìä Kleinste Eigenwerte des Kommutators: {eigvals_commutator[:10].cpu().numpy()}\")\n","\n","# üìå 3Ô∏è‚É£ √úberlappungsmatrix berechnen\n","overlap_matrix = H_eigenvectors.T @ T_eigenvectors\n","overlap_norm = torch.norm(overlap_matrix).item()\n","print(f\"üîç Norm der √úberlappungsmatrix: {overlap_norm:.6f}\")\n","\n","# üìå 4Ô∏è‚É£ Visualisierung der √úberlappungsmatrix\n","plt.figure(figsize=(6, 5))\n","sns.heatmap(overlap_matrix.cpu().numpy(), cmap=\"coolwarm\", center=0)\n","plt.title(\"√úberlappungsmatrix zwischen H und T\")\n","plt.xlabel(\"Index\")\n","plt.ylabel(\"Index\")\n","plt.colorbar(label=\"Matrixwerte\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":954},"id":"makWj6Tp4cSC","executionInfo":{"status":"error","timestamp":1742198243998,"user_tz":-60,"elapsed":3321,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"5b01a848-1bbe-4b10-b41a-9fac78a53483"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Norm des Kommutators [H, T]: 44.766060\n","üìä Kleinste Eigenwerte des Kommutators: [-4.0004215 -4.0002584 -3.99997   -3.9994705 -3.998855  -3.998063\n"," -3.997115  -3.9960241 -3.9947753 -3.9933467]\n","üîç Norm der √úberlappungsmatrix: 22.360708\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e4e2815ea2af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Matrixwerte\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mcolorbar\u001b[0;34m(mappable, cax, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2526\u001b[0m         \u001b[0mmappable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmappable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m             raise RuntimeError('No mappable was found to use for colorbar '\n\u001b[0m\u001b[1;32m   2529\u001b[0m                                \u001b[0;34m'creation. First define a mappable such as '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m                                \u001b[0;34m'an image (with imshow) or a contour set ('\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf)."]},{"output_type":"display_data","data":{"text/plain":["<Figure size 600x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(6, 5))\n","mappable = plt.imshow(overlap_matrix.cpu().numpy(), cmap=\"viridis\", aspect=\"auto\")\n","plt.colorbar(mappable, label=\"Matrixwerte\")  # Hier wird das \"mappable\" gesetzt\n","plt.xlabel(\"Index\")\n","plt.ylabel(\"Index\")\n","plt.title(\"√úberlappungsmatrix von H und T\")\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"id":"GFtXbGeN4rrE","executionInfo":{"status":"ok","timestamp":1742160974637,"user_tz":-60,"elapsed":824,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"47b47fd0-86fb-459c-9b7e-fe8453883aec"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x500 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","\n","# üîπ Differenz der Eigenwerte von H und T\n","delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","# üîπ Eigenvektordifferenznorm\n","eigenvector_diff_norm = torch.norm(eigenvectors_H - eigenvectors_T).item()\n","print(f\"üîç Norm der Eigenvektordifferenzmatrix: {eigenvector_diff_norm:.6f}\")\n","\n","# üîπ Test f√ºr verschiedene N\n","for test_N in [500, 1000]:\n","    print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {test_N}...\")\n","    # Hier Code f√ºr Neuberechnung mit anderem N"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RTHo2LtV5MLo","executionInfo":{"status":"ok","timestamp":1742161178006,"user_tz":-60,"elapsed":7,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"679f0fa4-b1ec-4e37-bf7c-88fa4c68783a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Spektrale Abweichung zwischen H und T: 0.000000\n","üîç Norm der Eigenvektordifferenzmatrix: 31.830872\n","\n","üß™ Teste Stabilit√§t f√ºr N = 500...\n","\n","üß™ Teste Stabilit√§t f√ºr N = 1000...\n"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken importieren\n","import torch\n","import numpy as np\n","import requests\n","import scipy.linalg as la\n","import gc\n","\n","# üìå GPU-Nutzung aktivieren\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM-Speicherfreigabe\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden (erste 500 oder 1000)\n","def load_zeta_zeros(N):\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    zeta_zeros = np.array([float(line.strip()) for line in response.text.split(\"\\n\") if line.strip()])[:N]\n","    return torch.tensor(zeta_zeros, dtype=torch.float32, device=device)\n","\n","# üìå Operator H (Hamilton-Matrix)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    H_diag = torch.diag(zeta_zeros)\n","    H_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return H_diag + H_offdiag\n","\n","# üìå Operator T (Beta-Skalen-Operator)\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    T_diag = torch.diag(beta_values)\n","    T_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return T_diag + T_offdiag\n","\n","# üìå Eigenwerte und Eigenvektoren berechnen\n","def compute_eigen(H, num_eigenvalues=500):\n","    eigenvalues, eigenvectors = torch.linalg.eigh(H)\n","    return eigenvalues[:num_eigenvalues], eigenvectors[:, :num_eigenvalues]\n","\n","# üìå Hauptprozess: Stabilit√§tstest f√ºr verschiedene N\n","for N in [50000, 100000]:\n","    print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\\n\")\n","\n","    # üîπ Speicher bereinigen\n","    free_vram()\n","\n","    # üîπ Zeta-Nullstellen laden\n","    zeta_zeros = load_zeta_zeros(N)\n","\n","    # üîπ Operatoren berechnen\n","    H = compute_H_operator(zeta_zeros)\n","    T = compute_T_operator(N)\n","\n","    # üîπ Eigenwerte & Eigenvektoren berechnen\n","    eigenvalues_H, eigenvectors_H = compute_eigen(H)\n","    eigenvalues_T, eigenvectors_T = compute_eigen(T)\n","\n","    # üîπ Spektrale Abweichung\n","    delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","    print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","    # üîπ Eigenvektordifferenzmatrix\n","    eigenvector_diff = torch.norm(eigenvectors_H - eigenvectors_T).item()\n","    print(f\"üîç Norm der Eigenvektordifferenzmatrix: {eigenvector_diff:.6f}\")\n","\n","    # üîπ Speicher erneut bereinigen\n","    free_vram()\n","\n","print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":885},"id":"Ft7Tt-QJ6LTh","executionInfo":{"status":"error","timestamp":1742161747193,"user_tz":-60,"elapsed":13014,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"f2564e11-669d-4786-cabf-0555760020c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","\n","üß™ Teste Stabilit√§t f√ºr N = 50000...\n","\n","üîç VRAM genutzt: 1.49 GB | VRAM reserviert: 1.49 GB | VRAM frei: 38.07 GB\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 9.31 GiB. GPU 0 has a total capacity of 39.56 GiB of which 284.88 MiB is free. Process 11807 has 39.27 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 6.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b491f26e1cca>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# üîπ Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# üîπ Eigenwerte & Eigenvektoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-b491f26e1cca>\u001b[0m in \u001b[0;36mcompute_T_operator\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mbeta_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mT_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mT_offdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mT_diag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT_offdiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.31 GiB. GPU 0 has a total capacity of 39.56 GiB of which 284.88 MiB is free. Process 11807 has 39.27 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 6.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken importieren\n","import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (GPU oder CPU)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå 1Ô∏è‚É£ Speicherbereinigung\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","# üìå 2Ô∏è‚É£ Zeta-Nullstellen laden (Dummy-Daten f√ºr Demo)\n","N_max = 50000  # Maximale Matrixgr√∂√üe\n","zeta_zeros = torch.linspace(1, N_max, N_max, device=device)  # Dummy-Daten\n","\n","# üìå 3Ô∏è‚É£ H-Operator berechnen (Hamilton-Matrix)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    H_diag = torch.diag(zeta_zeros)\n","    H_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return H_diag + H_offdiag\n","\n","# üìå 4Ô∏è‚É£ T-Operator als Sparse-Matrix berechnen\n","def compute_T_operator_sparse(N, device=\"cuda\"):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    indices = torch.tensor([\n","        list(range(N)),      # Hauptdiagonale\n","        list(range(N-1)),    # Obere Diagonale\n","        list(range(1, N))    # Untere Diagonale\n","    ], device=device)\n","\n","    values = torch.cat([\n","        beta_values,                   # Hauptdiagonale\n","        -torch.ones(N-1, device=device), # Obere Diagonale\n","        torch.ones(N-1, device=device)  # Untere Diagonale\n","    ])\n","\n","    size = (N, N)\n","    T_sparse = torch.sparse_coo_tensor(indices, values, size, device=device)\n","    return T_sparse\n","\n","# üìå 5Ô∏è‚É£ Hauptberechnung f√ºr verschiedene \\( N \\)\n","for N in [10_000, 20_000, 30_000, 40_000, 50_000]:\n","    print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","    # üîπ Speicherbereinigung\n","    free_vram()\n","\n","    # üîπ Operatoren berechnen\n","    try:\n","        H = compute_H_operator(zeta_zeros[:N])\n","        T = compute_T_operator_sparse(N)\n","\n","        # üîπ Eigenwerte berechnen\n","        eigenvalues_H, _ = torch.linalg.eigh(H)\n","        eigenvalues_T, _ = torch.linalg.eigh(T.to_dense())  # Sparse wird zu Dense f√ºr Eigensystem\n","\n","        # üîπ Berechnungen zur Korrelation\n","        delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","        eigenvector_norm = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","\n","        print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","        print(f\"üîç Norm der Eigenvektordifferenzmatrix: {eigenvector_norm:.6f}\")\n","\n","    except RuntimeError as e:\n","        print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","        break  # Stoppt, falls Speicherfehler auftritt\n","\n","print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":577},"id":"yEpqpAPX8ang","executionInfo":{"status":"error","timestamp":1742161955599,"user_tz":-60,"elapsed":358,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"c606aa38-7280-4d5c-84b4-8bdcb501e887"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n"]},{"output_type":"error","ename":"ValueError","evalue":"expected sequence of length 10000 at dim 1 (got 9999)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c5874da79de2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# üîπ Eigenwerte berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-c5874da79de2>\u001b[0m in \u001b[0;36mcompute_T_operator_sparse\u001b[0;34m(N, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mbeta_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     indices = torch.tensor([\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Hauptdiagonale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# Obere Diagonale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 10000 at dim 1 (got 9999)"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken importieren\n","import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (GPU oder CPU)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicherbereinigung\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","# üìå Dummy-Zeta-Nullstellen (f√ºr Test)\n","N_max = 50000\n","zeta_zeros = torch.linspace(1, N_max, N_max, device=device)\n","\n","# üìå Hamilton-Operator H\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    H_diag = torch.diag(zeta_zeros)\n","    H_offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return H_diag + H_offdiag\n","\n","# üìå Sparse \\( T \\)-Operator\n","def compute_T_operator_sparse(N, device=\"cuda\"):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    row_indices = torch.cat([\n","        torch.arange(N, device=device),  # Hauptdiagonale\n","        torch.arange(N-1, device=device),  # Obere Diagonale\n","        torch.arange(1, N, device=device)  # Untere Diagonale\n","    ])\n","\n","    col_indices = torch.cat([\n","        torch.arange(N, device=device),  # Hauptdiagonale\n","        torch.arange(1, N, device=device),  # Obere Diagonale\n","        torch.arange(N-1, device=device)  # Untere Diagonale\n","    ])\n","\n","    values = torch.cat([\n","        beta_values,  # Hauptdiagonale\n","        -torch.ones(N-1, device=device),  # Obere Diagonale\n","        torch.ones(N-1, device=device)  # Untere Diagonale\n","    ])\n","\n","    indices = torch.stack([row_indices, col_indices])  # Shape (2, Anzahl der Werte)\n","    size = (N, N)\n","\n","    return torch.sparse_coo_tensor(indices, values, size, device=device)\n","\n","# üìå Hauptberechnung f√ºr verschiedene \\( N \\)\n","for N in [10_000, 20_000, 30_000, 40_000, 50_000]:\n","    print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","    free_vram()  # üîπ Speicherbereinigung\n","\n","    try:\n","        H = compute_H_operator(zeta_zeros[:N])\n","        T = compute_T_operator_sparse(N)\n","\n","        eigenvalues_H, _ = torch.linalg.eigh(H)\n","        eigenvalues_T, _ = torch.linalg.eigh(T.to_dense())\n","\n","        delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","        eigenvector_norm = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","\n","        print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","        print(f\"üîç Norm der Eigenvektordifferenzmatrix: {eigenvector_norm:.6f}\")\n","\n","    except RuntimeError as e:\n","        print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","        break\n","\n","print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pIdxzfOR8tix","executionInfo":{"status":"ok","timestamp":1742162105381,"user_tz":-60,"elapsed":73762,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"997e7290-4ac5-4d63-95c9-fc57b42b8950"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç Spektrale Abweichung zwischen H und T: 0.000000\n","üîç Norm der Eigenvektordifferenzmatrix: 0.000000\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîç Spektrale Abweichung zwischen H und T: 0.000000\n","üîç Norm der Eigenvektordifferenzmatrix: 0.000000\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîç Spektrale Abweichung zwischen H und T: 0.000000\n","üîç Norm der Eigenvektordifferenzmatrix: 0.000000\n","\n","üß™ Teste Stabilit√§t f√ºr N = 40000...\n","‚ùå Speicherfehler bei N=40000: cusolver error: CUSOLVER_STATUS_INVALID_VALUE, when calling `cusolverDnXsyevd_bufferSize( handle, params, jobz, uplo, n, CUDA_R_32F, reinterpret_cast<const void*>(A), lda, CUDA_R_32F, reinterpret_cast<const void*>(W), CUDA_R_32F, workspaceInBytesOnDevice, workspaceInBytesOnHost)`. This error may appear if the input matrix contains NaN. If you keep seeing this error, you may use `torch.backends.cuda.preferred_linalg_library()` to try linear algebra operators with other supported backends. See https://pytorch.org/docs/stable/backends.html#torch.backends.cuda.preferred_linalg_library\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken importieren\n","import torch\n","import torch.nn.functional as F\n","import gc\n","\n","# üìå CUDA-Ger√§t pr√ºfen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicherfreigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - reserved\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen abrufen (reduziert auf 100.000 f√ºr GPU)\n","def load_zeta_zeros(N=100000):\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    data = torch.tensor(\n","        [float(line.strip()) for line in torch.hub.load_state_dict_from_url(url, progress=True).splitlines() if line.strip()],\n","        dtype=torch.float32, device=device\n","    )\n","    return data[:N] if len(data) > N else data\n","\n","# üìå Hamilton-Operator H erzeugen (Sparse)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.eye(N, device=device, dtype=torch.float32, diagonal=1) + torch.eye(N, device=device, dtype=torch.float32, diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå T-Operator als Sparse-Matrix definieren\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    indices = torch.tensor([\n","        list(range(N)),      # Hauptdiagonale\n","        list(range(N-1)),    # Obere Diagonale\n","        list(range(1, N))    # Untere Diagonale\n","    ], dtype=torch.long, device=device)\n","\n","    values = torch.cat([beta_values, torch.ones(N-1, device=device), -torch.ones(N-1, device=device)])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Eigenwerte berechnen (Sparse)\n","def compute_eigenvalues(matrix, N_eigen=500):\n","    matrix_dense = matrix.to_dense()\n","    eigenvalues, eigenvectors = torch.linalg.eigh(matrix_dense)\n","    return eigenvalues[:N_eigen], eigenvectors[:, :N_eigen]\n","\n","# üìå Stabilit√§tstests durchf√ºhren\n","def stability_test():\n","    for N in [10000, 20000, 30000, 40000]:\n","        free_vram()\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","            # üîπ Zeta-Nullstellen laden\n","            zeta_zeros = load_zeta_zeros(N)\n","\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros)\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ NaN-Pr√ºfung\n","            if torch.isnan(H.to_dense()).any() or torch.isnan(T.to_dense()).any():\n","                print(f\"‚ö†Ô∏è Matrix f√ºr N={N} enth√§lt NaN-Werte. Berechnung √ºbersprungen.\")\n","                continue\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = compute_eigenvalues(H)\n","            eigenvalues_T, _ = compute_eigenvalues(T)\n","\n","            # üîπ Abweichungen berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except torch.cuda.OutOfMemoryError:\n","            print(f\"‚ùå Speicherfehler bei N={N}, Berechnung abgebrochen.\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm starten\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"4mdFjGbH9gfg","executionInfo":{"status":"error","timestamp":1742162246245,"user_tz":-60,"elapsed":4041,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"6d631199-9c53-4863-b477-e61ccc30caa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.06 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","üîç VRAM genutzt: 10.06 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\" to /root/.cache/torch/hub/checkpoints/zeros6\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34.4M/34.4M [00:01<00:00, 18.5MB/s]\n"]},{"output_type":"error","ename":"UnpicklingError","evalue":"invalid load key, ' '.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-684e018144eb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mstability_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-684e018144eb>\u001b[0m in \u001b[0;36mstability_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# üîπ Zeta-Nullstellen laden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mzeta_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_zeta_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# üîπ Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-684e018144eb>\u001b[0m in \u001b[0;36mload_zeta_zeros\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     data = torch.tensor(\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_zip_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1496\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1742\u001b[0m         )\n\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, ' '."]}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import gc\n","import requests\n","\n","# üìå CUDA-Ger√§t pr√ºfen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicherfreigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - reserved\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå **Zeta-Nullstellen laden (Textdatei statt Torch-Checkpoint)**\n","def load_zeta_zeros(N=100000):\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","\n","    if response.status_code != 200:\n","        raise RuntimeError(f\"‚ùå Fehler beim Laden der Zeta-Nullstellen. HTTP {response.status_code}\")\n","\n","    # Nur numerische Werte aus der Datei extrahieren\n","    data = torch.tensor(\n","        [float(line.strip()) for line in response.text.splitlines() if line.strip()],\n","        dtype=torch.float32, device=device\n","    )\n","    return data[:N] if len(data) > N else data\n","\n","# üìå **Hamilton-Operator H (Sparse)**\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.eye(N, device=device, dtype=torch.float32, diagonal=1) + torch.eye(N, device=device, dtype=torch.float32, diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå **T-Operator als Sparse-Matrix**\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    indices = torch.tensor([\n","        list(range(N)),      # Hauptdiagonale\n","        list(range(N-1)),    # Obere Diagonale\n","        list(range(1, N))    # Untere Diagonale\n","    ], dtype=torch.long, device=device)\n","\n","    values = torch.cat([beta_values, torch.ones(N-1, device=device), -torch.ones(N-1, device=device)])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå **Eigenwerte berechnen (Sparse)**\n","def compute_eigenvalues(matrix, N_eigen=500):\n","    matrix_dense = matrix.to_dense()\n","    eigenvalues, eigenvectors = torch.linalg.eigh(matrix_dense)\n","    return eigenvalues[:N_eigen], eigenvectors[:, :N_eigen]\n","\n","# üìå **Stabilit√§tstests durchf√ºhren**\n","def stability_test():\n","    for N in [10000, 20000, 30000, 40000]:\n","        free_vram()\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","            # üîπ Zeta-Nullstellen laden (korrekt √ºber HTTP)\n","            zeta_zeros = load_zeta_zeros(N)\n","\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros)\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ NaN-Pr√ºfung\n","            if torch.isnan(H.to_dense()).any() or torch.isnan(T.to_dense()).any():\n","                print(f\"‚ö†Ô∏è Matrix f√ºr N={N} enth√§lt NaN-Werte. Berechnung √ºbersprungen.\")\n","                continue\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = compute_eigenvalues(H)\n","            eigenvalues_T, _ = compute_eigenvalues(T)\n","\n","            # üîπ Abweichungen berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except torch.cuda.OutOfMemoryError:\n","            print(f\"‚ùå Speicherfehler bei N={N}, Berechnung abgebrochen.\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå **Hauptprogramm starten**\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":819},"id":"rfX3kQqR93HE","executionInfo":{"status":"error","timestamp":1742162352272,"user_tz":-60,"elapsed":13923,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"ffe509ab-03de-4db8-a12d-3af693ef6d66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.06 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","üîç VRAM genutzt: 10.06 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n"]},{"output_type":"error","ename":"TypeError","evalue":"eye() received an invalid combination of arguments - got (int, diagonal=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-2b773b33c23d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mstability_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-2b773b33c23d>\u001b[0m in \u001b[0;36mstability_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# üîπ Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2b773b33c23d>\u001b[0m in \u001b[0;36mcompute_H_operator\u001b[0;34m(zeta_zeros)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0moffdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffdiag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: eye() received an invalid combination of arguments - got (int, diagonal=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","\n","# üìå CUDA-Ger√§t pr√ºfen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicherfreigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - reserved\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå **Zeta-Nullstellen laden (Textdatei statt Torch-Checkpoint)**\n","def load_zeta_zeros(N=100000):\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","\n","    if response.status_code != 200:\n","        raise RuntimeError(f\"‚ùå Fehler beim Laden der Zeta-Nullstellen. HTTP {response.status_code}\")\n","\n","    # Nur numerische Werte aus der Datei extrahieren\n","    data = torch.tensor(\n","        [float(line.strip()) for line in response.text.splitlines() if line.strip()],\n","        dtype=torch.float32, device=device\n","    )\n","    return data[:N] if len(data) > N else data\n","\n","# üìå **Hamilton-Operator H (Sparse)**\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device, dtype=torch.float32), diagonal=1) + \\\n","              torch.diag(torch.ones(N-1, device=device, dtype=torch.float32), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå **T-Operator als Sparse-Matrix**\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    indices = torch.tensor([\n","        list(range(N)),      # Hauptdiagonale\n","        list(range(N-1)),    # Obere Diagonale\n","        list(range(1, N))    # Untere Diagonale\n","    ], dtype=torch.long, device=device)\n","\n","    values = torch.cat([beta_values, torch.ones(N-1, device=device), -torch.ones(N-1, device=device)])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå **Eigenwerte berechnen (Sparse)**\n","def compute_eigenvalues(matrix, N_eigen=500):\n","    matrix_dense = matrix.to_dense()\n","    eigenvalues, eigenvectors = torch.linalg.eigh(matrix_dense)\n","    return eigenvalues[:N_eigen], eigenvectors[:, :N_eigen]\n","\n","# üìå **Stabilit√§tstests durchf√ºhren**\n","def stability_test():\n","    for N in [10000, 20000, 30000, 40000]:\n","        free_vram()\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","            # üîπ Zeta-Nullstellen laden (korrekt √ºber HTTP)\n","            zeta_zeros = load_zeta_zeros(N)\n","\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros)\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ NaN-Pr√ºfung\n","            if torch.isnan(H.to_dense()).any() or torch.isnan(T.to_dense()).any():\n","                print(f\"‚ö†Ô∏è Matrix f√ºr N={N} enth√§lt NaN-Werte. Berechnung √ºbersprungen.\")\n","                continue\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = compute_eigenvalues(H)\n","            eigenvalues_T, _ = compute_eigenvalues(T)\n","\n","            # üîπ Abweichungen berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except torch.cuda.OutOfMemoryError:\n","            print(f\"‚ùå Speicherfehler bei N={N}, Berechnung abgebrochen.\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå **Hauptprogramm starten**\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":585},"id":"LkDwaHeX-QIq","executionInfo":{"status":"error","timestamp":1742162451445,"user_tz":-60,"elapsed":13441,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"f54b69d3-9b87-4c2b-ba5d-78487e2b1986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n"]},{"output_type":"error","ename":"ValueError","evalue":"expected sequence of length 10000 at dim 1 (got 9999)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6a252b19ad79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mstability_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-6a252b19ad79>\u001b[0m in \u001b[0;36mstability_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# üîπ Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# üîπ NaN-Pr√ºfung\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-6a252b19ad79>\u001b[0m in \u001b[0;36mcompute_T_operator_sparse\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mbeta_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     indices = torch.tensor([\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Hauptdiagonale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# Obere Diagonale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 10000 at dim 1 (got 9999)"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","\n","# üìå CUDA-Ger√§t pr√ºfen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicherfreigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - reserved\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå **Zeta-Nullstellen laden**\n","def load_zeta_zeros(N=100000):\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","\n","    if response.status_code != 200:\n","        raise RuntimeError(f\"‚ùå Fehler beim Laden der Zeta-Nullstellen. HTTP {response.status_code}\")\n","\n","    # Nur numerische Werte extrahieren\n","    data = torch.tensor(\n","        [float(line.strip()) for line in response.text.splitlines() if line.strip()],\n","        dtype=torch.float32, device=device\n","    )\n","    return data[:N] if len(data) > N else data\n","\n","# üìå **Hamilton-Operator H (Sparse)**\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device, dtype=torch.float32), diagonal=1) + \\\n","              torch.diag(torch.ones(N-1, device=device, dtype=torch.float32), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå **T-Operator als Sparse-Matrix (Fehler behoben)**\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    # Indizes mit richtiger L√§nge erzeugen\n","    indices = torch.cat([\n","        torch.arange(N, device=device).unsqueeze(0),      # Hauptdiagonale (N Werte)\n","        torch.arange(N-1, device=device).unsqueeze(0),    # Obere Diagonale (N-1 Werte)\n","        torch.arange(1, N, device=device).unsqueeze(0)    # Untere Diagonale (N-1 Werte)\n","    ], dim=0)\n","\n","    values = torch.cat([beta_values, torch.ones(N-1, device=device), -torch.ones(N-1, device=device)])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå **Eigenwerte berechnen (Sparse)**\n","def compute_eigenvalues(matrix, N_eigen=500):\n","    matrix_dense = matrix.to_dense()\n","    eigenvalues, eigenvectors = torch.linalg.eigh(matrix_dense)\n","    return eigenvalues[:N_eigen], eigenvectors[:, :N_eigen]\n","\n","# üìå **Stabilit√§tstests durchf√ºhren**\n","def stability_test():\n","    for N in [10000, 20000, 30000, 40000]:\n","        free_vram()\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","            # üîπ Zeta-Nullstellen laden\n","            zeta_zeros = load_zeta_zeros(N)\n","\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros)\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ NaN-Pr√ºfung\n","            if torch.isnan(H.to_dense()).any() or torch.isnan(T.to_dense()).any():\n","                print(f\"‚ö†Ô∏è Matrix f√ºr N={N} enth√§lt NaN-Werte. Berechnung √ºbersprungen.\")\n","                continue\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = compute_eigenvalues(H)\n","            eigenvalues_T, _ = compute_eigenvalues(T)\n","\n","            # üîπ Abweichungen berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except torch.cuda.OutOfMemoryError:\n","            print(f\"‚ùå Speicherfehler bei N={N}, Berechnung abgebrochen.\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå **Hauptprogramm starten**\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":657},"id":"Y8_dX2yl-shp","executionInfo":{"status":"error","timestamp":1742162573139,"user_tz":-60,"elapsed":12795,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"176d700c-b2c9-46c7-ac28-16a599325a04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.07 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","üîç VRAM genutzt: 10.07 GB | VRAM reserviert: 13.42 GB | VRAM frei: 26.14 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Sizes of tensors must match except in dimension 0. Expected size 10000 but got size 9999 for tensor number 1 in the list.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-8cb793c03da2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mstability_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-8cb793c03da2>\u001b[0m in \u001b[0;36mstability_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# üîπ Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# üîπ NaN-Pr√ºfung\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-8cb793c03da2>\u001b[0m in \u001b[0;36mcompute_T_operator_sparse\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Indizes mit richtiger L√§nge erzeugen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     indices = torch.cat([\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Hauptdiagonale (N Werte)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# Obere Diagonale (N-1 Werte)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 10000 but got size 9999 for tensor number 1 in the list."]}]},{"cell_type":"code","source":["# üìå **1Ô∏è‚É£ Notwendige Bibliotheken importieren**\n","import torch\n","import gc\n","import requests\n","import numpy as np\n","import scipy.sparse as sp\n","import scipy.sparse.linalg as spla\n","\n","# üìå **2Ô∏è‚É£ Ger√§t w√§hlen (GPU oder CPU)**\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå **3Ô∏è‚É£ VRAM-Speicher bereinigen**\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    torch.cuda.synchronize()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå **4Ô∏è‚É£ Zeta-Nullstellen von Odlyzko-Server laden**\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    print(f\"üåê Lade Zeta-Nullstellen von {url}...\")\n","    response = requests.get(url)\n","    zeta_zeros = np.array([float(line.strip()) for line in response.text.splitlines() if line.strip()])\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return torch.tensor(zeta_zeros, dtype=torch.float32, device=device)\n","\n","# üìå **5Ô∏è‚É£ Sparse Hamilton-Operator H berechnen**\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.eye(N, device=device, dtype=torch.float32, k=1) + torch.eye(N, device=device, dtype=torch.float32, k=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå **6Ô∏è‚É£ Sparse T-Operator definieren**\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    # **Indizes f√ºr Sparse-Darstellung**\n","    row_indices = torch.cat([\n","        torch.arange(N, device=device),    # Hauptdiagonale\n","        torch.arange(N-1, device=device),  # Obere Diagonale\n","        torch.arange(1, N, device=device)  # Untere Diagonale\n","    ])\n","\n","    col_indices = torch.cat([\n","        torch.arange(N, device=device),    # Hauptdiagonale\n","        torch.arange(1, N, device=device), # Obere Diagonale\n","        torch.arange(N-1, device=device)   # Untere Diagonale\n","    ])\n","\n","    values = torch.cat([\n","        beta_values,                        # Hauptdiagonale\n","        torch.ones(N-1, device=device),     # Obere Diagonale\n","        -torch.ones(N-1, device=device)     # Untere Diagonale\n","    ])\n","\n","    indices = torch.stack([row_indices, col_indices])  # Indizes korrekt stapeln\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå **7Ô∏è‚É£ Stabilit√§tstest f√ºr verschiedene Matrixgr√∂√üen**\n","def stability_test():\n","    N_values = [10000, 20000, 30000]  # **Teste verschiedene Werte f√ºr \\( N \\)**\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in N_values:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            free_vram()\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = torch.linalg.eigh(H.to_dense())\n","            eigenvalues_T, _ = torch.linalg.eigh(T.to_dense())\n","\n","            # üîπ Spektrale Abweichung berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            norm_diff = torch.norm(H.to_dense() - T.to_dense()).item()\n","\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {norm_diff:.6f}\")\n","\n","        except RuntimeError as e:\n","            print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå **8Ô∏è‚É£ Hauptprogramm starten**\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":855},"id":"ObYqZaBw_cdx","executionInfo":{"status":"error","timestamp":1742162765861,"user_tz":-60,"elapsed":12801,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"5bb71521-d938-4ea5-dbee-fdfb698cc2bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.07 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.49 GB\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç VRAM genutzt: 10.08 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.48 GB\n"]},{"output_type":"error","ename":"TypeError","evalue":"eye() received an invalid combination of arguments - got (int, k=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-26293e0539f1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mstability_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-26293e0539f1>\u001b[0m in \u001b[0;36mstability_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mfree_vram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-26293e0539f1>\u001b[0m in \u001b[0;36mcompute_H_operator\u001b[0;34m(zeta_zeros)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0moffdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffdiag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: eye() received an invalid combination of arguments - got (int, k=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"]}]},{"cell_type":"code","source":["# üìå **1Ô∏è‚É£ Notwendige Bibliotheken importieren**\n","import torch\n","import gc\n","import requests\n","import numpy as np\n","\n","# üìå **2Ô∏è‚É£ Ger√§t w√§hlen (GPU oder CPU)**\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå **3Ô∏è‚É£ VRAM-Speicher bereinigen**\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    torch.cuda.synchronize()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå **4Ô∏è‚É£ Zeta-Nullstellen von Odlyzko-Server laden**\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    print(f\"üåê Lade Zeta-Nullstellen von {url}...\")\n","    response = requests.get(url)\n","    zeta_zeros = np.array([float(line.strip()) for line in response.text.splitlines() if line.strip()])\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return torch.tensor(zeta_zeros, dtype=torch.float32, device=device)\n","\n","# üìå **5Ô∏è‚É£ Sparse Hamilton-Operator H berechnen**\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)  # Diagonale der Matrix\n","\n","    # **Korrektur: Erzeuge manuell die Nebendiagonalen**\n","    offdiag_upper = torch.diag(torch.ones(N-1, device=device), diagonal=1)\n","    offdiag_lower = torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","\n","    return (diag + offdiag_upper + offdiag_lower).to_sparse()\n","\n","# üìå **6Ô∏è‚É£ Sparse T-Operator definieren**\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    row_indices = torch.cat([\n","        torch.arange(N, device=device),    # Hauptdiagonale\n","        torch.arange(N-1, device=device),  # Obere Diagonale\n","        torch.arange(1, N, device=device)  # Untere Diagonale\n","    ])\n","\n","    col_indices = torch.cat([\n","        torch.arange(N, device=device),    # Hauptdiagonale\n","        torch.arange(1, N, device=device), # Obere Diagonale\n","        torch.arange(N-1, device=device)   # Untere Diagonale\n","    ])\n","\n","    values = torch.cat([\n","        beta_values,                        # Hauptdiagonale\n","        torch.ones(N-1, device=device),     # Obere Diagonale\n","        -torch.ones(N-1, device=device)     # Untere Diagonale\n","    ])\n","\n","    indices = torch.stack([row_indices, col_indices])  # Indizes korrekt stapeln\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå **7Ô∏è‚É£ Stabilit√§tstest f√ºr verschiedene Matrixgr√∂√üen**\n","def stability_test():\n","    N_values = [10000, 20000, 30000]  # **Teste verschiedene Werte f√ºr \\( N \\)**\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in N_values:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            free_vram()\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H, _ = torch.linalg.eigh(H.to_dense())\n","            eigenvalues_T, _ = torch.linalg.eigh(T.to_dense())\n","\n","            # üîπ Spektrale Abweichung berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            norm_diff = torch.norm(H.to_dense() - T.to_dense()).item()\n","\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {norm_diff:.6f}\")\n","\n","        except RuntimeError as e:\n","            print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå **8Ô∏è‚É£ Hauptprogramm starten**\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hWXI84E3_3Z5","executionInfo":{"status":"ok","timestamp":1742162925186,"user_tz":-60,"elapsed":59551,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"ea9af759-a564-4534-ac40-49063e26c5b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç VRAM genutzt: 10.45 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","üîç Spektrale Abweichung zwischen H und T: 37822.722656\n","üîç Norm der Eigenvektordifferenzmatrix: 37823.265625\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîç VRAM genutzt: 10.82 GB | VRAM reserviert: 13.42 GB | VRAM frei: 28.73 GB\n","üîç Spektrale Abweichung zwischen H und T: 118174.156250\n","üîç Norm der Eigenvektordifferenzmatrix: 118174.484375\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîç VRAM genutzt: 11.94 GB | VRAM reserviert: 14.91 GB | VRAM frei: 27.61 GB\n","‚ùå Speicherfehler bei N=30000: CUDA out of memory. Tried to allocate 10.07 GiB. GPU 0 has a total capacity of 39.56 GiB of which 8.83 GiB is free. Process 11807 has 30.72 GiB memory in use. Of the allocated memory 20.51 GiB is allocated by PyTorch, and 9.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken\n","import torch\n","import scipy.sparse as sp\n","import scipy.sparse.linalg as spla\n","import requests\n","import gc\n","\n","# üìå Ger√§t ausw√§hlen (GPU oder CPU)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM-Freigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen aus dem Internet laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    zeros = [float(line.strip()) for line in response.text.split(\"\\n\") if line.strip()]\n","    return torch.tensor(zeros, dtype=torch.float32, device=device)\n","\n","# üìå Sparse-Hamilton-Operator \\( H \\)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.eye(N, device=device)[:-1, :-1] + torch.eye(N, device=device)[1:, 1:]\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Sparse-T-Operator \\( T \\)\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.eye(N, device=device)[:-1, :-1] - torch.eye(N, device=device)[1:, 1:]\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Haupt-Stabilit√§tstest\n","def stability_test():\n","    zeta_zeros = load_zeta_zeros()\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","    for N in [10000, 20000, 30000]:\n","        free_vram()\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H = spla.eigsh(H.to_dense().cpu().numpy(), k=5, which=\"SM\", return_eigenvectors=False)\n","            eigenvalues_T = spla.eigsh(T.to_dense().cpu().numpy(), k=5, which=\"SM\", return_eigenvectors=False)\n","\n","            # üîπ Differenzanalyse\n","            delta_lambda = torch.norm(torch.tensor(eigenvalues_H) - torch.tensor(eigenvalues_T)).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","            # üîπ Eigenvektordifferenzmatrix\n","            norm_eigenvector_diff = torch.norm(H.to_dense() - T.to_dense()).item()\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {norm_eigenvector_diff:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Code ausf√ºhren\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLsCZvI8Am7P","executionInfo":{"status":"ok","timestamp":1742163065675,"user_tz":-60,"elapsed":12922,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"679b6677-46f8-4cde-b74f-5e1db99fa962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîç VRAM genutzt: 10.45 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Speicherfehler bei N=10000: The size of tensor a (10000) must match the size of tensor b (9999) at non-singleton dimension 1\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken\n","import torch\n","import scipy.sparse.linalg as spla\n","import requests\n","import gc\n","\n","# üìå Ger√§t ausw√§hlen (GPU oder CPU)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM-Freigabe-Funktion\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen aus dem Internet laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    zeros = [float(line.strip()) for line in response.text.split(\"\\n\") if line.strip()]\n","    return torch.tensor(zeros, dtype=torch.float32, device=device)\n","\n","# üìå Sparse-Hamilton-Operator \\( H \\)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Sparse-T-Operator \\( T \\) (mit behobenem Index-Fehler)\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Haupt-Stabilit√§tstest\n","def stability_test():\n","    zeta_zeros = load_zeta_zeros()\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","    for N in [10000, 20000, 30000]:\n","        free_vram()\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator_sparse(N)\n","\n","            # üîπ Eigenwerte berechnen\n","            eigenvalues_H = spla.eigsh(H.to_dense().cpu().numpy(), k=5, which=\"SM\", return_eigenvectors=False)\n","            eigenvalues_T = spla.eigsh(T.to_dense().cpu().numpy(), k=5, which=\"SM\", return_eigenvectors=False)\n","\n","            # üîπ Differenzanalyse\n","            delta_lambda = torch.norm(torch.tensor(eigenvalues_H) - torch.tensor(eigenvalues_T)).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","            # üîπ Eigenvektordifferenzmatrix\n","            norm_eigenvector_diff = torch.norm(H.to_dense() - T.to_dense()).item()\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {norm_eigenvector_diff:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Code ausf√ºhren\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5oKV9gfoA55o","executionInfo":{"status":"ok","timestamp":1742163865118,"user_tz":-60,"elapsed":731744,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"246200cc-bb54-47df-9e12-1d532a3336cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîç VRAM genutzt: 10.45 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç Spektrale Abweichung zwischen H und T: 52.084339\n","üîç Norm der Eigenvektordifferenzmatrix: 37823.265625\n","üîç VRAM genutzt: 10.45 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîç Spektrale Abweichung zwischen H und T: 51.996162\n","üîç Norm der Eigenvektordifferenzmatrix: 118174.484375\n","üîç VRAM genutzt: 10.45 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.10 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîç Spektrale Abweichung zwischen H und T: 51.101719\n","üîç Norm der Eigenvektordifferenzmatrix: 335701.031250\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# GPU Speicher freigeben (falls noch belegt)\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# RAM-Nutzung optimieren\n","del H, T  # Falls noch im Speicher\n","gc.collect()\n","\n","# Status pr√ºfen\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HTMnUNujFmbs","executionInfo":{"status":"ok","timestamp":1742164364240,"user_tz":-60,"elapsed":183,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"5a226ba1-bbe3-4ae6-ec48-118020653b1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç VRAM genutzt: 10.44 GB | VRAM reserviert: 13.42 GB | VRAM frei: 29.11 GB\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import scipy.sparse as sp\n","import scipy.sparse.linalg as spla\n","import gc\n","\n","# ‚úÖ 1Ô∏è‚É£ RAM-Speicher bereinigen\n","def free_ram():\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","# ‚úÖ 2Ô∏è‚É£ Ger√§t auf CPU setzen\n","device = \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# ‚úÖ 3Ô∏è‚É£ Zeta-Nullstellen laden (2 Mio Nullstellen)\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    data = np.loadtxt(url, max_rows=2_000_000)  # 2 Millionen Nullstellen\n","    return torch.tensor(data, dtype=torch.float32, device=device)\n","\n","# ‚úÖ 4Ô∏è‚É£ Hamilton-Operator \\( H \\) berechnen (Sparse-Matrix)\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = sp.diags(zeta_zeros.numpy(), format=\"csr\")  # Diagonale aus Nullstellen\n","    offdiag = sp.diags([np.ones(N-1), np.ones(N-1)], offsets=[-1, 1], format=\"csr\")  # Nebendiagonale\n","    return diag + offdiag\n","\n","# ‚úÖ 5Ô∏è‚É£ T-Operator \\( T \\) berechnen (Sparse-Matrix)\n","def compute_T_operator(N):\n","    beta_values = np.linspace(1, N, N)\n","    diag = sp.diags(beta_values, format=\"csr\")  # Diagonale mit Beta-Skala\n","    offdiag = sp.diags([np.ones(N-1), -np.ones(N-1)], offsets=[-1, 1], format=\"csr\")  # Nebendiagonale\n","    return diag + offdiag\n","\n","# ‚úÖ 6Ô∏è‚É£ Eigenwerte berechnen\n","def compute_eigenvalues(operator, num_eigenvalues=500):\n","    eigenvalues = spla.eigsh(operator, k=num_eigenvalues, which=\"SA\", return_eigenvectors=False)\n","    return torch.tensor(eigenvalues, dtype=torch.float32, device=device)\n","\n","# ‚úÖ 7Ô∏è‚É£ Stabilit√§tstest f√ºr verschiedene \\( N \\)\n","def stability_test():\n","    free_ram()\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in [10_000, 20_000, 50_000, 100_000]:\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","            free_ram()\n","\n","            # Hamilton- und T-Operator erstellen\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            # Eigenwerte berechnen\n","            eigenvalues_H = compute_eigenvalues(H, 500)\n","            eigenvalues_T = compute_eigenvalues(T, 500)\n","\n","            # Spektrale Abweichung berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","            # Eigenvektordifferenz berechnen\n","            norm_eigenvectors = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {norm_eigenvectors:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Speicherfehler bei N={N}: {e}\")\n","            break\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# ‚úÖ **Main Execution**\n","if __name__ == \"__main__\":\n","    free_ram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZHw5c17MF88w","executionInfo":{"status":"ok","timestamp":1742167036758,"user_tz":-60,"elapsed":1496345,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"8729beb9-4074-4df7-98ec-a433a5c285ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cpu\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç Spektrale Abweichung zwischen H und T: 4954.430176\n","üîç Norm der Eigenvektordifferenzmatrix: 4954.430176\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîç Spektrale Abweichung zwischen H und T: 4953.630371\n","üîç Norm der Eigenvektordifferenzmatrix: 4953.630371\n","\n","üß™ Teste Stabilit√§t f√ºr N = 50000...\n","üîç Spektrale Abweichung zwischen H und T: 4953.254395\n","üîç Norm der Eigenvektordifferenzmatrix: 4953.254395\n","\n","üß™ Teste Stabilit√§t f√ºr N = 100000...\n","üîç Spektrale Abweichung zwischen H und T: 4952.929199\n","üîç Norm der Eigenvektordifferenzmatrix: 4952.929199\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen: CUDA f√ºr GPU-Berechnung\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","free_vram()\n","\n","# üìå Testparameter\n","N = 100_000  # Matrixgr√∂√üe\n","\n","# üìå Zeta-Nullstellen simulieren (echte Daten k√∂nnen hier geladen werden)\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Funktionen zur Operator-Berechnung\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.eye(N, device=device, dtype=torch.float32)\n","    H = diag + offdiag\n","    return H.to_sparse()\n","\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den Operator T als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.eye(N, device=device, dtype=torch.float32)\n","    T = diag + offdiag\n","    return T.to_sparse()\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Operatoren berechnen\n","H = compute_H_operator(zeta_zeros)\n","T = compute_T_operator(N)\n","\n","# üìå Eigenwerte berechnen (nur die kleinsten 500)\n","eigenvalues_H = torch.linalg.eigvalsh(H.to_dense())[:500]\n","eigenvalues_T = torch.linalg.eigvalsh(T.to_dense())[:500]\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":723},"id":"2-0bgtAe_dG_","executionInfo":{"status":"error","timestamp":1742167713500,"user_tz":-60,"elapsed":118,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"7fac62d9-7083-41d6-8a1c-5042ba4dbe58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 2.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-4b1365708a28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# üìå Operatoren berechnen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_H_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_T_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-4b1365708a28>\u001b[0m in \u001b[0;36mcompute_H_operator\u001b[0;34m(zeta_zeros)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m\"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0moffdiag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffdiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 2.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen: CUDA f√ºr GPU-Berechnung\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","free_vram()\n","\n","# üìå Testparameter\n","N = 100_000  # Matrixgr√∂√üe\n","\n","# üìå Zeta-Nullstellen simulieren (echte Daten k√∂nnen hier geladen werden)\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Funktionen zur Sparse-Operator-Berechnung\n","def compute_H_operator_sparse(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = zeta_zeros  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","def compute_T_operator_sparse(N):\n","    \"\"\" Erzeugt den Operator T als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = beta_values  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Sparse-Operatoren berechnen\n","H = compute_H_operator_sparse(zeta_zeros)\n","T = compute_T_operator_sparse(N)\n","\n","# üìå Eigenwerte berechnen (nur die kleinsten 500)\n","eigenvalues_H = torch.linalg.eigvalsh(H.to_dense())[:500]\n","eigenvalues_T = torch.linalg.eigvalsh(T.to_dense())[:500]\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"e-53iZQFSxNu","executionInfo":{"status":"error","timestamp":1742167818857,"user_tz":-60,"elapsed":122,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"6b52b6d1-f07b-4bc3-ecdf-e8c79ed6c587"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.11 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-4aaa497d325d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# üìå Eigenwerte berechnen (nur die kleinsten 500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvalsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0meigenvalues_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvalsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.11 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen: CUDA f√ºr GPU-Berechnung\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","free_vram()\n","\n","# üìå Testparameter\n","N = 100_000  # Matrixgr√∂√üe\n","\n","# üìå Zeta-Nullstellen simulieren (echte Daten k√∂nnen hier geladen werden)\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Funktionen zur Sparse-Operator-Berechnung\n","def compute_H_operator_sparse(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = zeta_zeros  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","def compute_T_operator_sparse(N):\n","    \"\"\" Erzeugt den Operator T als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = beta_values  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Sparse-Operatoren berechnen\n","H = compute_H_operator_sparse(zeta_zeros)\n","T = compute_T_operator_sparse(N)\n","\n","# üìå Speicher bereinigen & freigeben\n","free_vram()\n","\n","# üìå Eigenwerte berechnen (um VRAM zu schonen, nur die kleinsten 500)\n","print(\"‚è≥ Berechne Eigenwerte von H und T...\")\n","eigenvalues_H = torch.linalg.eigvalsh(H.to_dense())[:500]\n","eigenvalues_T = torch.linalg.eigvalsh(T.to_dense())[:500]\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"id":"hgV9G9PWTMuq","executionInfo":{"status":"error","timestamp":1742169063392,"user_tz":-60,"elapsed":160,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"8e24c4f5-e49c-41b5-bd97-74b6b5774009","colab":{"base_uri":"https://localhost:8080/","height":669}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.11 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.12 GB\n","‚è≥ Berechne Eigenwerte von H und T...\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.11 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-ccaafec7a298>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# üìå Eigenwerte berechnen (um VRAM zu schonen, nur die kleinsten 500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚è≥ Berechne Eigenwerte von H und T...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvalsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0meigenvalues_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigvalsh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 37.25 GiB. GPU 0 has a total capacity of 39.56 GiB of which 31.58 GiB is free. Process 11807 has 7.97 GiB memory in use. Of the allocated memory 4.11 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei (theoretisch): {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKXnmWr_Xe6I","executionInfo":{"status":"ok","timestamp":1742169088225,"user_tz":-60,"elapsed":45,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"e4313a7d-1605-45b5-a13c-9f7275321be9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç VRAM genutzt: 4.11 GB | VRAM reserviert: 7.46 GB | VRAM frei (theoretisch): 35.45 GB\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen: CUDA f√ºr GPU-Berechnung\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","free_vram()\n","\n","# üìå Matrixgr√∂√üe (Testparameter)\n","N = 100_000  # Matrixgr√∂√üe, skalierbar bis GPU-Limit\n","\n","# üìå Zeta-Nullstellen simulieren (echte Daten k√∂nnen hier geladen werden)\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Sparse-Operator-Funktionen\n","def compute_H_operator_sparse(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = zeta_zeros  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","def compute_T_operator_sparse(N):\n","    \"\"\" Erzeugt den Operator T als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    # üîπ Indizes f√ºr die Diagonale (i, i)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = beta_values  # Diagonalwerte\n","\n","    # üîπ Indizes f√ºr Nebendiagonalen (i, i+1) und (i+1, i)\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    # üîπ Gesamtindizes & Werte\n","    indices = torch.cat([torch.stack([row, col]), torch.stack([row_off, col_off]), torch.stack([col_off, row_off])], dim=1)\n","    values = torch.cat([values, values_off, values_off])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Sparse-Operatoren berechnen\n","H = compute_H_operator_sparse(zeta_zeros)\n","T = compute_T_operator_sparse(N)\n","\n","# üìå Speicher bereinigen & freigeben\n","free_vram()\n","\n","# üìå Eigenwerte mit `torch.lobpcg` (Speichert effizient!)\n","print(\"‚è≥ Berechne Eigenwerte von H und T...\")\n","X = torch.randn(N, 500, device=device)  # Zuf√§llige Startvektoren\n","\n","eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)  # Nur 500 Eigenwerte\n","eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"id":"n72KWMS6YOrv","executionInfo":{"status":"error","timestamp":1742169248856,"user_tz":-60,"elapsed":208,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"39e16522-aae3-4e56-e748-d674174016ed","colab":{"base_uri":"https://localhost:8080/","height":711}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.11 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.12 GB\n","‚è≥ Berechne Eigenwerte von H und T...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-c9968713d79a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zuf√§llige Startvektoren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Nur 500 Eigenwerte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen: CUDA f√ºr GPU-Berechnung\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","free_vram()\n","\n","# üìå Matrixgr√∂√üe (Testparameter)\n","N = 100_000  # Matrixgr√∂√üe\n","\n","# üìå Zeta-Nullstellen simulieren (echte Daten k√∂nnen hier geladen werden)\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Sparse-Operator-Funktionen\n","def compute_H_operator_sparse(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = zeta_zeros  # Diagonalwerte\n","\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([row, col]),\n","        torch.stack([row_off, col_off]),\n","        torch.stack([col_off, row_off])\n","    ], dim=1)\n","\n","    values = torch.cat([values, values_off, values_off])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","def compute_T_operator_sparse(N):\n","    \"\"\" Erzeugt den Operator T als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = beta_values  # Diagonalwerte\n","\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([row, col]),\n","        torch.stack([row_off, col_off]),\n","        torch.stack([col_off, row_off])\n","    ], dim=1)\n","\n","    values = torch.cat([values, values_off, values_off])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Sparse-Operatoren berechnen\n","H = compute_H_operator_sparse(zeta_zeros)\n","T = compute_T_operator_sparse(N)\n","\n","# üìå Speicher bereinigen & freigeben\n","free_vram()\n","\n","# üìå Dynamische Anzahl der Eigenwerte\n","k = min(N // 3, 500)  # Mindestens 3-mal kleiner als N\n","\n","# üìå Eigenwerte mit `torch.lobpcg` (Speichert effizient!)\n","print(f\"‚è≥ Berechne {k} kleinste Eigenwerte von H und T...\")\n","X = torch.randn(N, k, device=device)  # Zuf√§llige Startvektoren\n","\n","eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":711},"id":"tSmU43SqYn7n","executionInfo":{"status":"error","timestamp":1742169347791,"user_tz":-60,"elapsed":223,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"838fce20-3f31-45d5-de33-6a5132ef8762"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.30 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.31 GB\n","‚è≥ Berechne 500 kleinste Eigenwerte von H und T...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-71f45a267976>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Zuf√§llige Startvektoren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import time\n","\n","# üìå Ger√§t setzen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","free_vram()\n","\n","# üìå Matrixgr√∂√üe\n","N = 100_000\n","\n","# üìå Zeta-Nullstellen simulieren\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå Sparse-Operatoren definieren\n","def compute_H_operator_sparse(zeta_zeros):\n","    N = len(zeta_zeros)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = zeta_zeros  # Diagonale\n","\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([row, col]),\n","        torch.stack([row_off, col_off]),\n","        torch.stack([col_off, row_off])\n","    ], dim=1)\n","\n","    values = torch.cat([values, values_off, values_off])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","def compute_T_operator_sparse(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    row = torch.arange(N, device=device)\n","    col = torch.arange(N, device=device)\n","    values = beta_values\n","\n","    row_off = torch.arange(N-1, device=device)\n","    col_off = torch.arange(1, N, device=device)\n","    values_off = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([row, col]),\n","        torch.stack([row_off, col_off]),\n","        torch.stack([col_off, row_off])\n","    ], dim=1)\n","\n","    values = torch.cat([values, values_off, values_off])\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Starte Zeitmessung\n","start_time = time.time()\n","\n","# üìå Sparse-Operatoren berechnen\n","H = compute_H_operator_sparse(zeta_zeros)\n","T = compute_T_operator_sparse(N)\n","\n","# üìå Speicher bereinigen & freigeben\n","free_vram()\n","\n","# üìå Dynamische Anzahl der Eigenwerte\n","k = min(N // 3, 500)\n","\n","# üìå Eigenwerte mit `torch.lobpcg`\n","print(f\"‚è≥ Berechne {k} kleinste Eigenwerte von H und T...\")\n","X = torch.randn(N, k, device=device, dtype=torch.float32)  # ‚úÖ FIXED\n","\n","eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","# üìå Berechnungszeit messen\n","end_time = time.time()\n","gpu_time = end_time - start_time\n","\n","# üìå Ergebnisse ausgeben\n","print(f\"‚è≥ Berechnungszeit auf GPU: {gpu_time:.2f} Sekunden\")\n","print(f\"üîç Erste 10 Eigenwerte von H: {eigenvalues_H[:10]}\")\n","print(f\"üîç Erste 10 Eigenwerte von T: {eigenvalues_T[:10]}\")\n","\n","# üìå VRAM-Status nach Berechnung\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"id":"ZLoe7W0PZA19","executionInfo":{"status":"error","timestamp":1742169455949,"user_tz":-60,"elapsed":252,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"216a365c-38a0-48cb-cb8c-3e8853622dd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.30 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.31 GB\n","‚è≥ Berechne 500 kleinste Eigenwerte von H und T...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-44481dc73555>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ‚úÖ FIXED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (CUDA, falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Funktion zur VRAM-Freigabe\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {used:.2f} GB | Reserviert: {reserved:.2f} GB | Frei: {free:.2f} GB\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()  # VRAM aufr√§umen\n","\n","    # Parameter\n","    N_list = [10_000, 20_000, 30_000]  # Testgr√∂√üen\n","    k = 500  # Anzahl der Eigenwerte\n","\n","    for N in N_list:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            zeta_zeros = torch.linspace(1, N, N, device=device)  # Dummy-Zeta-Nullstellen\n","            H = compute_H_operator(zeta_zeros)\n","            T = compute_T_operator(N)\n","\n","            # üîπ Eigenwerte berechnen\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","            eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","            # üîπ Ergebnisse\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Funktion zur Berechnung des H-Operators\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Funktion zur Berechnung des T-Operators\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yk-jFTZ8cMq2","executionInfo":{"status":"ok","timestamp":1742170292029,"user_tz":-60,"elapsed":73,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"983a510d-4f71-4f94-9f9f-57d638cab600"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.30 GB | Reserviert: 7.46 GB | Frei: 35.26 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (CUDA, falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Funktion zur VRAM-Freigabe\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {used:.2f} GB | Reserviert: {reserved:.2f} GB | Frei: {free:.2f} GB\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()  # VRAM aufr√§umen\n","\n","    # Parameter\n","    N_list = [10_000, 20_000, 30_000]  # Testgr√∂√üen\n","    k = 500  # Anzahl der Eigenwerte\n","\n","    for N in N_list:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            zeta_zeros = torch.linspace(1, N, N, device=device)  # Dummy-Zeta-Nullstellen\n","            H = compute_H_operator(zeta_zeros).to_dense()  # üîÑ Konvertiere Sparse-Matrix zu Dense\n","            T = compute_T_operator(N).to_dense()\n","\n","            # üîπ Eigenwerte berechnen\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            if H.shape[0] < 3 * X.shape[1]:  # Fix f√ºr `lobpcg()`\n","                raise ValueError(f\"‚ùå Fehler: N={N} ist zu klein f√ºr `lobpcg()` (m < 3*k).\")\n","\n","            eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","            # üîπ Ergebnisse\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Funktion zur Berechnung des H-Operators\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Funktion zur Berechnung des T-Operators\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypKB1fwNcNsS","executionInfo":{"status":"ok","timestamp":1742170410211,"user_tz":-60,"elapsed":203,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"62bbbd43-3cd6-4aed-cf36-883d5cefcef4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 4.35 GB | Reserviert: 8.95 GB | Frei: 35.21 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (CUDA, falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Funktion zur VRAM-Freigabe\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {used:.2f} GB | Reserviert: {reserved:.2f} GB | Frei: {free:.2f} GB\")\n","\n","# üìå Funktion zur Berechnung des H-Operators (Sparse-Matrix)\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Funktion zur Berechnung des T-Operators (Sparse-Matrix)\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()  # VRAM aufr√§umen\n","\n","    # Parameter\n","    N_list = [10_000, 20_000, 30_000]  # Testgr√∂√üen\n","    k = 500  # Anzahl der Eigenwerte\n","\n","    for N in N_list:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            zeta_zeros = torch.linspace(1, N, N, device=device)  # Dummy-Zeta-Nullstellen\n","            H = compute_H_operator(zeta_zeros).to_dense()  # üîÑ Konvertiere Sparse-Matrix zu Dense\n","            T = compute_T_operator(N).to_dense()\n","\n","            # üîπ Eigenwerte berechnen\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            if H.shape[0] < 3 * X.shape[1]:  # Fix f√ºr `lobpcg()`\n","                raise ValueError(f\"‚ùå Fehler: N={N} ist zu klein f√ºr `lobpcg()` (m < 3*k).\")\n","\n","            eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","            # üîπ Ergebnisse\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lF7s-LMNdBw4","executionInfo":{"status":"ok","timestamp":1742170508473,"user_tz":-60,"elapsed":470,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"fa1bb615-78d5-4aba-b500-9212e4deb2c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 11.06 GB | Reserviert: 15.65 GB | Frei: 28.50 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå Ger√§t w√§hlen (CUDA, falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Funktion zur VRAM-Freigabe\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","    free = total - used\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {used:.2f} GB | Reserviert: {reserved:.2f} GB | Frei: {free:.2f} GB\")\n","\n","# üìå Funktion zur Berechnung des H-Operators (Sparse-Matrix)\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Funktion zur Berechnung des T-Operators (Sparse-Matrix)\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    return (diag + offdiag).to_sparse()\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()  # VRAM aufr√§umen\n","\n","    # Parameter\n","    N_list = [10_000, 20_000, 30_000]  # Testgr√∂√üen\n","    k = 500  # Anzahl der Eigenwerte\n","\n","    for N in N_list:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            # üîπ Operatoren berechnen\n","            zeta_zeros = torch.linspace(1, N, N, device=device)  # Dummy-Zeta-Nullstellen\n","            H = compute_H_operator(zeta_zeros).to_dense()  # üîÑ Konvertiere Sparse-Matrix zu Dense\n","            T = compute_T_operator(N).to_dense()\n","\n","            # üîπ Eigenwerte berechnen\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            # ‚ùó FIX: Korrekte Bedingung f√ºr `lobpcg()`\n","            if int(H.shape[0]) < 3 * int(X.shape[1]):\n","                raise ValueError(f\"‚ùå Fehler: N={N} ist zu klein f√ºr `lobpcg()` (m < 3*k).\")\n","\n","            eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","            # üîπ Ergebnisse\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aFfJQe55dXlm","executionInfo":{"status":"ok","timestamp":1742170596808,"user_tz":-60,"elapsed":484,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"2ecf3546-a5c3-48f7-fb47-5a839dd89478"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 11.06 GB | Reserviert: 15.65 GB | Frei: 28.50 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå GPU-Speicher freigeben\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Testgr√∂√üe\n","N = 10_000\n","k = 500  # Anzahl der Eigenwerte\n","\n","# üìå Dummy-Zeta-Nullstellen\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå H-Operator als dichte Matrix\n","H = torch.diag(zeta_zeros) + torch.eye(N, device=device, dtype=torch.float32, diagonal=1) + torch.eye(N, device=device, dtype=torch.float32, diagonal=-1)\n","\n","# üìå T-Operator als dichte Matrix\n","beta_values = torch.linspace(1, N, N, device=device)\n","T = torch.diag(beta_values) + torch.eye(N, device=device, dtype=torch.float32, diagonal=1) - torch.eye(N, device=device, dtype=torch.float32, diagonal=-1)\n","\n","# üìå Zuf√§llige Startvektoren\n","X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","# üìå FIXED: Bedingung f√ºr `lobpcg()`\n","if int(H.shape[0]) < 3 * int(X.shape[1]):\n","    raise ValueError(f\"‚ùå Fehler: N={N} ist zu klein f√ºr `lobpcg()` (m < 3*k).\")\n","\n","# üìå Berechnung der Eigenwerte\n","eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","# üìå Ergebnisse\n","delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")"],"metadata":{"id":"mctvFzL5dwMi","executionInfo":{"status":"error","timestamp":1742170701697,"user_tz":-60,"elapsed":110,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"b080ce78-67d0-43b2-9258-04627edeca4c","colab":{"base_uri":"https://localhost:8080/","height":595}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n"]},{"output_type":"error","ename":"TypeError","evalue":"eye() received an invalid combination of arguments - got (int, diagonal=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-9bece9b2149a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# üìå H-Operator als dichte Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeta_zeros\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# üìå T-Operator als dichte Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: eye() received an invalid combination of arguments - got (int, diagonal=int, dtype=torch.dtype, device=torch.device), but expected one of:\n * (int n, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n * (int n, int m, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","# üìå GPU-Speicher freigeben\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå Testgr√∂√üe\n","N = 10_000\n","k = 500  # Anzahl der Eigenwerte\n","\n","# üìå Dummy-Zeta-Nullstellen\n","zeta_zeros = torch.linspace(1, N, N, device=device)\n","\n","# üìå H-Operator als dichte Matrix (Fix: `eye()` mit zwei Argumenten)\n","H = torch.diag(zeta_zeros) + torch.eye(N, N, device=device, dtype=torch.float32) + torch.eye(N, N, device=device, dtype=torch.float32)\n","\n","# üìå T-Operator als dichte Matrix (Fix: `eye()` mit zwei Argumenten)\n","beta_values = torch.linspace(1, N, N, device=device)\n","T = torch.diag(beta_values) + torch.eye(N, N, device=device, dtype=torch.float32) - torch.eye(N, N, device=device, dtype=torch.float32)\n","\n","# üìå Zuf√§llige Startvektoren\n","X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","# üìå FIXED: Bedingung f√ºr `lobpcg()`\n","if int(H.shape[0]) < 3 * int(X.shape[1]):\n","    raise ValueError(f\"‚ùå Fehler: N={N} ist zu klein f√ºr `lobpcg()` (m < 3*k).\")\n","\n","# üìå Berechnung der Eigenwerte\n","eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","# üìå Ergebnisse\n","delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":619},"id":"xNNuFN8GeCQs","executionInfo":{"status":"error","timestamp":1742170767919,"user_tz":-60,"elapsed":27,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"945f66f1-e461-431e-fec2-b6fc67112c17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-9c779d9b097f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# üìå Berechnung der Eigenwerte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","# VRAM-Status ausgeben\n","used = torch.cuda.memory_allocated() / 1024**3\n","reserved = torch.cuda.memory_reserved() / 1024**3\n","total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n","free = total - used\n","\n","print(f\"üîç VRAM genutzt: {used:.2f} GB | VRAM reserviert: {reserved:.2f} GB | VRAM frei: {free:.2f} GB\")"],"metadata":{"id":"inhDOmY0ebOk","executionInfo":{"status":"ok","timestamp":1742170873551,"user_tz":-60,"elapsed":90,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"c0b3c419-e319-43e9-c2ac-ad32f7758952","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç VRAM genutzt: 4.86 GB | VRAM reserviert: 5.59 GB | VRAM frei: 34.69 GB\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywNkkvXM6bAU","executionInfo":{"status":"ok","timestamp":1742161432199,"user_tz":-60,"elapsed":124,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"d194163e-d4a0-478b-9c3e-586c031f7d74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}]},{"cell_type":"code","source":["eigenvalues_H, eigenvectors_H = torch.linalg.eigh(H)\n","eigenvalues_T, eigenvectors_T = torch.linalg.eigh(T)"],"metadata":{"id":"n92HKPms5cVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"H.shape: {H.shape}, X.shape: {X.shape}\")"],"metadata":{"id":"7T-wAhyje4vi","executionInfo":{"status":"ok","timestamp":1742171160214,"user_tz":-60,"elapsed":51,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"a153f9af-0e0c-48a9-807c-b20601dd896a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["H.shape: torch.Size([10000, 10000]), X.shape: torch.Size([10000, 100])\n"]}]},{"cell_type":"code","source":["eigenvalues_H, _ = torch.lobpcg(H, X, largest=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3xPbCGbrfR_A","executionInfo":{"status":"error","timestamp":1742171170826,"user_tz":-60,"elapsed":84,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"b26bd10f-8dc2-4166-d928-4898531a5a84"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"Could not run 'aten::gt.Scalar' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::gt.Scalar' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, NestedTensorCPU, NestedTensorCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nUndefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMeta: registered at /dev/null:241 [kernel]\nFPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nVulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMetal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nCustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nNestedTensorCPU: registered at /pytorch/build/aten/src/ATen/RegisterNestedTensorCPU.cpp:873 [kernel]\nNestedTensorCUDA: registered at /pytorch/build/aten/src/ATen/RegisterNestedTensorCUDA.cpp:1009 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:17801 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesBinaryOps.cpp:349 [kernel]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-97f81cba9eaf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::gt.Scalar' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::gt.Scalar' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, NestedTensorCPU, NestedTensorCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched,...\n\nUndefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\nHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMeta: registered at /dev/null:241 [kernel]\nFPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nVulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMetal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nQuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nCustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nSparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\nNestedTensorCPU: registered at /pytorch/build/aten/src/ATen/RegisterNestedTensorCPU.cpp:873 [kernel]\nNestedTensorCUDA: registered at /pytorch/build/aten/src/ATen/RegisterNestedTensorCUDA.cpp:1009 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:20142 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:17801 [kernel]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesBinaryOps.cpp:349 [kernel]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n"]}]},{"cell_type":"code","source":["H_dense = H.to_dense()\n","T_dense = T.to_dense()\n","\n","X = torch.randn(H_dense.shape[0], k, device=device, dtype=torch.float32)\n","eigenvalues_H, _ = torch.lobpcg(H_dense, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T_dense, X, largest=False)"],"metadata":{"id":"HvL7bcvsf8yG","executionInfo":{"status":"error","timestamp":1742171266754,"user_tz":-60,"elapsed":6,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"a6dbaa6f-906b-494d-80a1-22271ab1960a","colab":{"base_uri":"https://localhost:8080/","height":601}},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-c8277c443c78>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["k = min(H_dense.shape[0] // 3, 500)  # Maximal 1/3 von N oder 500\n","X = torch.randn(H_dense.shape[0], k, device=device, dtype=torch.float32)\n","eigenvalues_H, _ = torch.lobpcg(H_dense, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T_dense, X, largest=False)"],"metadata":{"id":"6u-DxzlYgPFN","executionInfo":{"status":"error","timestamp":1742171344886,"user_tz":-60,"elapsed":19,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"8cd3a33e-fdaa-46ec-bd24-d3e503fff4f9","colab":{"base_uri":"https://localhost:8080/","height":619}},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-da0ab1b0488d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Maximal 1/3 von N oder 500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["k = min(H_dense.shape[0] // 3 - 1, 500)  # Sicherheitspuffer -1\n","X = torch.randn(H_dense.shape[0], k, device=device, dtype=torch.float32)\n","eigenvalues_H, _ = torch.lobpcg(H_dense, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T_dense, X, largest=False)"],"metadata":{"id":"5hpFVjdUgfQ1","executionInfo":{"status":"error","timestamp":1742171408524,"user_tz":-60,"elapsed":38,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"ed727feb-4496-43e5-d41e-8a03cda78c38","colab":{"base_uri":"https://localhost:8080/","height":619}},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-1b918710d86c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sicherheitspuffer -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["X = X.to_sparse()"],"metadata":{"id":"ULJXGhT9fbxS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k = min(H_dense.shape[0] // 5, 250)  # Konservativer Ansatz\n","X = torch.randn(H_dense.shape[0], k, device=device, dtype=torch.float32)\n","\n","eigenvalues_H, _ = torch.lobpcg(H_dense, X, largest=False)\n","eigenvalues_T, _ = torch.lobpcg(T_dense, X, largest=False)"],"metadata":{"id":"XQ1n5jJMhDPW","executionInfo":{"status":"error","timestamp":1742171557631,"user_tz":-60,"elapsed":22,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"19629881-a696-442f-a643-8406b0116066","colab":{"base_uri":"https://localhost:8080/","height":601}},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Boolean value of Tensor with more than one value is ambiguous","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-da943c134555>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0meigenvalues_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0meigenvalues_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlobpcg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_dense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36mlobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    562\u001b[0m             )\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     return _lobpcg(\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_lobpcg.py\u001b[0m in \u001b[0;36m_lobpcg\u001b[0;34m(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         raise ValueError(\n\u001b[1;32m    616\u001b[0m             \u001b[0;34mf\"LPBPCG algorithm is not applicable when the number of A rows (={m})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"]}]},{"cell_type":"code","source":["!pip install torch scipy numpy matplotlib requests"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZas3GYphtCt","executionInfo":{"status":"ok","timestamp":1742171805892,"user_tz":-60,"elapsed":75065,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"ad9ea0c3-8221-4bd2-8ef1-7d2a945e80cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["\n","# üìå Importiere Bibliotheken\n","import torch\n","import numpy as np\n","import scipy.sparse as sp\n","import scipy.sparse.linalg as sla\n","import requests\n","import gc\n","import time\n","\n","# üìå Ger√§t ausw√§hlen (GPU bevorzugt, sonst CPU)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    vram_used = torch.cuda.memory_allocated() / 1024**3\n","    vram_reserved = torch.cuda.memory_reserved() / 1024**3\n","    vram_free = torch.cuda.get_device_properties(0).total_memory / 1024**3 - vram_used\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {vram_used:.2f} GB | Reserviert: {vram_reserved:.2f} GB | Frei: {vram_free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden (bis zu 2 Mio)\n","def load_zeta_zeros(url=\"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\", max_zeros=2000000):\n","    print(f\"üåê Lade Zeta-Nullstellen von {url}...\")\n","    response = requests.get(url)\n","    zeta_zeros = np.array([float(line) for line in response.text.splitlines() if line.strip()])[:max_zeros]\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return torch.tensor(zeta_zeros, dtype=torch.float32, device=device)\n","\n","# üìå Sparse H-Operator erzeugen\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.tensor(zeta_zeros, device=device)\n","    offdiag = torch.ones(N - 1, device=device)\n","    indices = torch.tensor([list(range(N)), list(range(N))], device=device)\n","    values = torch.cat([diag, offdiag, offdiag])\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return H\n","\n","# üìå Sparse T-Operator erzeugen\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.tensor(beta_values, device=device)\n","    offdiag = torch.ones(N - 1, device=device)\n","    indices = torch.tensor([list(range(N)), list(range(N))], device=device)\n","    values = torch.cat([diag, offdiag, -offdiag])\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return T\n","\n","# üìå Eigenwerte berechnen (LOBPCG oder Fallback auf eigsh)\n","def compute_eigenvalues(A, k=500):\n","    try:\n","        X = torch.randn(A.shape[0], k, device=device, dtype=torch.float32)\n","        eigenvalues, _ = torch.lobpcg(A, X, largest=False)\n","        return eigenvalues\n","    except RuntimeError as e:\n","        print(f\"‚ö†Ô∏è LOBPCG fehlgeschlagen: {e}, wechsle zu SciPy eigsh...\")\n","        A_dense = A.to_dense().cpu().numpy()\n","        eigenvalues = sla.eigsh(A_dense, k=k, which=\"SA\", return_eigenvectors=False)\n","        return torch.tensor(eigenvalues, dtype=torch.float32, device=device)\n","\n","# üìå Stabilit√§tstest f√ºr verschiedene N\n","def stability_test():\n","    N_values = [10000, 20000, 30000]\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in N_values:\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","            free_vram()\n","\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            eigenvalues_H = compute_eigenvalues(H)\n","            eigenvalues_T = compute_eigenvalues(T)\n","\n","            spectral_deviation = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {spectral_deviation:.6f}\")\n","\n","            free_vram()\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm ausf√ºhren\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqvFOlznimLq","executionInfo":{"status":"ok","timestamp":1742172097161,"user_tz":-60,"elapsed":12583,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"adcf5a5f-8830-4a54-eedb-e1bc3931a6cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2000000 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=10000: indices and values must have same nnz, but got nnz from indices: 10000, nnz from values: 29998\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=20000: indices and values must have same nnz, but got nnz from indices: 20000, nnz from values: 59998\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=30000: indices and values must have same nnz, but got nnz from indices: 30000, nnz from values: 89998\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-e4db49732f04>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  diag = torch.tensor(zeta_zeros, device=device)\n"]}]},{"cell_type":"code","source":["# üìå Notwendige Bibliotheken importieren\n","import torch\n","import gc\n","import requests\n","\n","# üìå Ger√§t automatisch erkennen (CUDA oder CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM-Speicher freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    torch.cuda.synchronize()\n","    used = torch.cuda.memory_allocated() / 1024**3\n","    reserved = torch.cuda.memory_reserved() / 1024**3\n","    total = torch.cuda.get_device_properties(0).total_memory / 1024**3 if device.type == \"cuda\" else 0\n","    free = total - used if total > 0 else 0\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {used:.2f} GB | Reserviert: {reserved:.2f} GB | Frei: {free:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros(url=\"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\", max_zeros=2_000_000):\n","    print(f\"üåê Lade Zeta-Nullstellen von {url}...\")\n","    response = requests.get(url)\n","    data = response.text.splitlines()\n","    zeta_zeros = torch.tensor([float(line.strip()) for line in data[:max_zeros]], device=device)\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return zeta_zeros\n","\n","# üìå Sparse H-Operator erstellen\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag_indices = torch.arange(N, device=device)\n","    offdiag_indices = torch.arange(N - 1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([diag_indices, diag_indices]),        # Hauptdiagonale\n","        torch.stack([offdiag_indices, offdiag_indices + 1]),  # Obere Nebendiagonale\n","        torch.stack([offdiag_indices + 1, offdiag_indices])   # Untere Nebendiagonale\n","    ], dim=1)\n","\n","    values = torch.cat([\n","        zeta_zeros,               # Hauptdiagonale\n","        torch.ones(N - 1, device=device),  # Obere Nebendiagonale\n","        torch.ones(N - 1, device=device)   # Untere Nebendiagonale\n","    ])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Sparse T-Operator erstellen\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag_indices = torch.arange(N, device=device)\n","    offdiag_indices = torch.arange(N - 1, device=device)\n","\n","    indices = torch.cat([\n","        torch.stack([diag_indices, diag_indices]),        # Hauptdiagonale\n","        torch.stack([offdiag_indices, offdiag_indices + 1]),  # Obere Nebendiagonale\n","        torch.stack([offdiag_indices + 1, offdiag_indices])   # Untere Nebendiagonale\n","    ], dim=1)\n","\n","    values = torch.cat([\n","        beta_values,              # Hauptdiagonale\n","        torch.ones(N - 1, device=device),  # Obere Nebendiagonale\n","        -torch.ones(N - 1, device=device)  # Untere Nebendiagonale\n","    ])\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Eigenwerte berechnen\n","def compute_eigenvalues(H, T, k=500):\n","    N = H.shape[0]\n","    X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","    eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","    eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","    return eigenvalues_H[:k], eigenvalues_T[:k]\n","\n","# üìå Stabilit√§tstests\n","def stability_test():\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","        free_vram()\n","\n","        try:\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","            eigenvalues_H, eigenvalues_T = compute_eigenvalues(H, T)\n","\n","            spectral_deviation = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            eigenvector_deviation = torch.norm(eigenvalues_H).item()\n","\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {spectral_deviation:.6f}\")\n","            print(f\"üîç Norm der Eigenvektordifferenzmatrix: {eigenvector_deviation:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {str(e)}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtV15FYA3WGr","executionInfo":{"status":"ok","timestamp":1742194204682,"user_tz":-60,"elapsed":21525,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"73a5da04-3f19-460f-af1d-0cd13fc6e95d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2000000 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","\n","# üìå Ger√§t ausw√§hlen (CUDA falls verf√ºgbar, sonst CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB | \"\n","          f\"Reserviert: {torch.cuda.memory_reserved() / 1024**3:.2f} GB | Frei: {torch.cuda.get_device_properties(0).total_memory / 1024**3 - torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","# üìå Debug-Funktion\n","def debug_tensor(tensor, name=\"Tensor\"):\n","    \"\"\" Hilfsfunktion zur Debugging-Ausgabe von Tensoren \"\"\"\n","    print(f\"\\nüîç {name}:\")\n","    print(f\"  - Shape: {tensor.shape}\")\n","    print(f\"  - dtype: {tensor.dtype}\")\n","    print(f\"  - Device: {tensor.device}\")\n","    print(f\"  - Min: {tensor.min().item() if tensor.numel() > 0 else 'N/A'}\")\n","    print(f\"  - Max: {tensor.max().item() if tensor.numel() > 0 else 'N/A'}\")\n","    print(f\"  - Mean: {tensor.mean().item() if tensor.numel() > 0 else 'N/A'}\")\n","    print(f\"  - NaN vorhanden? {'Ja' if torch.isnan(tensor).any() else 'Nein'}\")\n","\n","    if tensor.numel() <= 10:  # Nur kleine Tensoren vollst√§ndig ausgeben\n","        print(f\"  - Werte: {tensor.cpu().numpy()}\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    print(f\"\\nüåê Lade Zeta-Nullstellen von {url}...\")\n","\n","    response = requests.get(url)\n","    zeta_zeros = torch.tensor([float(line) for line in response.text.splitlines() if line.strip()], device=device)\n","\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return zeta_zeros\n","\n","# üìå H-Operator als Sparse-Matrix erstellen\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    H = diag + offdiag\n","    return H.to_sparse()\n","\n","# üìå T-Operator als Sparse-Matrix erstellen\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    T = diag + offdiag\n","    return T.to_sparse()\n","\n","# üìå Stabilit√§tstest\n","def stability_test():\n","    free_vram()\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","            free_vram()\n","\n","            # üìå Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            debug_tensor(H, \"Hamilton-Operator H\")\n","            debug_tensor(T, \"T-Operator\")\n","\n","            # üìå Eigenwerte berechnen\n","            k = min(N // 3 - 1, 500)  # Sicherheitspuffer\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","            debug_tensor(eigenvalues_H, \"Eigenwerte von H\")\n","            debug_tensor(eigenvalues_T, \"Eigenwerte von T\")\n","\n","            # üìå Unterschiede berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"id":"mvTuqQXC45Sk","executionInfo":{"status":"ok","timestamp":1742194602334,"user_tz":-60,"elapsed":13668,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"427ce0b5-1ada-48ea-96c1-47225ae14cc7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=10000: Could not run 'aten::min' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::min' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14971 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesReduceOps.cpp:449 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=20000: Could not run 'aten::min' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::min' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14971 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesReduceOps.cpp:449 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.03 GB | Frei: 39.55 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=30000: Could not run 'aten::min' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::min' is only available for these backends: [CPU, CUDA, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:19588 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:14971 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesReduceOps.cpp:449 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","\n","# üìå Ger√§t w√§hlen (CUDA falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","def free_vram():\n","    \"\"\" Speicherfreigabe auf der GPU \"\"\"\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB | \"\n","          f\"Reserviert: {torch.cuda.memory_reserved() / 1024**3:.2f} GB | Frei: {torch.cuda.get_device_properties(0).total_memory / 1024**3 - torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","def debug_tensor(tensor, name=\"Tensor\"):\n","    \"\"\" Debugging-Ausgabe von Tensoren \"\"\"\n","    tensor_dense = tensor.to_dense() if tensor.is_sparse else tensor  # In Dense umwandeln\n","    print(f\"\\nüîç {name}:\")\n","    print(f\"  - Shape: {tensor_dense.shape}\")\n","    print(f\"  - dtype: {tensor_dense.dtype}\")\n","    print(f\"  - Device: {tensor_dense.device}\")\n","    print(f\"  - Min: {tensor_dense.min().item() if tensor_dense.numel() > 0 else 'N/A'}\")\n","    print(f\"  - Max: {tensor_dense.max().item() if tensor_dense.numel() > 0 else 'N/A'}\")\n","    print(f\"  - Mean: {tensor_dense.mean().item() if tensor_dense.numel() > 0 else 'N/A'}\")\n","    print(f\"  - NaN vorhanden? {'Ja' if torch.isnan(tensor_dense).any() else 'Nein'}\")\n","\n","def load_zeta_zeros():\n","    \"\"\" L√§dt die Zeta-Nullstellen von einer externen Quelle \"\"\"\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    print(f\"\\nüåê Lade Zeta-Nullstellen von {url}...\")\n","    response = requests.get(url)\n","    zeta_zeros = torch.tensor([float(line) for line in response.text.splitlines() if line.strip()], device=device)\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","    return zeta_zeros\n","\n","def compute_H_operator(zeta_zeros):\n","    \"\"\" Erzeugt den Hamilton-Operator H als Sparse-Matrix \"\"\"\n","    N = len(zeta_zeros)\n","    diag = torch.diag(zeta_zeros)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) + torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    H = diag + offdiag\n","    return H.to_sparse()\n","\n","def compute_T_operator(N):\n","    \"\"\" Erzeugt den T-Operator als Sparse-Matrix \"\"\"\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = torch.diag(beta_values)\n","    offdiag = torch.diag(torch.ones(N-1, device=device), diagonal=1) - torch.diag(torch.ones(N-1, device=device), diagonal=-1)\n","    T = diag + offdiag\n","    return T.to_sparse()\n","\n","def stability_test():\n","    \"\"\" Testet die Stabilit√§t f√ºr verschiedene Matrixgr√∂√üen \"\"\"\n","    free_vram()\n","    zeta_zeros = load_zeta_zeros()\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","            free_vram()\n","\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            debug_tensor(H, \"Hamilton-Operator H\")\n","            debug_tensor(T, \"T-Operator\")\n","\n","            k = min(N // 3 - 1, 500)\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","            debug_tensor(eigenvalues_H, \"Eigenwerte von H\")\n","            debug_tensor(eigenvalues_T, \"Eigenwerte von T\")\n","\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"id":"vUB-m4DG53E4","executionInfo":{"status":"ok","timestamp":1742194855432,"user_tz":-60,"elapsed":14125,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"e88d7382-33a3-4e7a-c639-6492d7722b35","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","\n","üåê Lade Zeta-Nullstellen von https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: 0.0\n","  - Max: 9877.7822265625\n","  - Mean: 0.5328838229179382\n","  - NaN vorhanden? Nein\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: -1.0\n","  - Max: 10000.0\n","  - Mean: 0.5000500082969666\n","  - NaN vorhanden? Nein\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.03 GB | Reserviert: 0.39 GB | Frei: 39.53 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: 0.0\n","  - Max: 18046.46484375\n","  - Mean: 0.48365092277526855\n","  - NaN vorhanden? Nein\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: -1.0\n","  - Max: 20000.0\n","  - Mean: 0.5000249743461609\n","  - NaN vorhanden? Nein\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.05 GB | Reserviert: 0.40 GB | Frei: 39.51 GB\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: 0.0\n","  - Max: 25755.34765625\n","  - Mean: 0.4586336612701416\n","  - NaN vorhanden? Nein\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","  - Min: -1.0\n","  - Max: 30000.0\n","  - Mean: 0.5000166296958923\n","  - NaN vorhanden? Nein\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","import numpy as np\n","\n","# üìå Ger√§t festlegen (CUDA, falls verf√ºgbar)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1024**3:.2f} GB | Reserviert: {torch.cuda.memory_reserved() / 1024**3:.2f} GB | Frei: {torch.cuda.get_device_properties(0).total_memory / 1024**3 - torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n","\n","free_vram()\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    zeta_zeros = np.loadtxt(response.iter_lines(), dtype=np.float32)\n","    return torch.tensor(zeta_zeros, device=device)\n","\n","zeta_zeros = load_zeta_zeros()\n","print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","# üìå H-Operator als Sparse-Matrix\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = torch.tensor(zeta_zeros, device=device).clone().detach()\n","    offdiag = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([torch.arange(N).unsqueeze(0), torch.arange(N).unsqueeze(0)], dim=0)\n","    values = torch.cat([diag, offdiag, offdiag])\n","\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32)\n","    return H\n","\n","# üìå T-Operator als Sparse-Matrix\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","    diag = beta_values.clone().detach()\n","    offdiag = torch.ones(N-1, device=device)\n","\n","    indices = torch.cat([torch.arange(N).unsqueeze(0), torch.arange(N).unsqueeze(0)], dim=0)\n","    values = torch.cat([diag, offdiag, -offdiag])\n","\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32)\n","    return T\n","\n","# üìå Stabilit√§tstest\n","def stability_test():\n","    for N in [10_000, 20_000, 30_000]:\n","        try:\n","            free_vram()\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","            # Operatoren berechnen\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            # Sparse zu Dense (lobpcg ben√∂tigt Dense)\n","            if H.is_sparse:\n","                H = H.to_dense()\n","            if T.is_sparse:\n","                T = T.to_dense()\n","\n","            # Zuf√§llige Startvektoren\n","            k = min(N // 3 - 1, 500)  # Sicherheitspuffer\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","\n","            # Eigenwerte berechnen\n","            eigenvalues_H, _ = torch.lobpcg(H, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T, X, largest=False)\n","\n","            # Ergebnisse ausgeben\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm starten\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"id":"Fx5FtrPO6sSo","executionInfo":{"status":"ok","timestamp":1742195064046,"user_tz":-60,"elapsed":3335,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"4f60ecf7-a163-4129-cb7d-99ddf837edb8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 39.56 GB\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument values in method wrapper_SparseCUDA___sparse_coo_tensor_with_dims_and_tensors)\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument values in method wrapper_SparseCUDA___sparse_coo_tensor_with_dims_and_tensors)\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 39.55 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument values in method wrapper_SparseCUDA___sparse_coo_tensor_with_dims_and_tensors)\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-a67628de3c47>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  diag = torch.tensor(zeta_zeros, device=device).clone().detach()\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","import numpy as np\n","\n","# üìå GPU-Check\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1e9:.2f} GB | Reserviert: {torch.cuda.memory_reserved() / 1e9:.2f} GB | Frei: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    data = np.fromstring(response.text, sep=\"\\n\")\n","    return torch.tensor(data, dtype=torch.float32, device=device)\n","\n","# üìå Hamilton-Operator H\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","\n","    # ‚úÖ Alle Tensoren auf `device` setzen\n","    diag = zeta_zeros.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    indices = torch.cat([\n","        torch.arange(N, device=device).unsqueeze(0),\n","        torch.arange(N, device=device).unsqueeze(0)\n","    ], dim=0)\n","\n","    values = torch.cat([diag, offdiag, offdiag])\n","\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return H\n","\n","# üìå T-Operator T\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device, dtype=torch.float32)\n","    diag = beta_values.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    indices = torch.cat([\n","        torch.arange(N, device=device).unsqueeze(0),\n","        torch.arange(N, device=device).unsqueeze(0)\n","    ], dim=0)\n","\n","    values = torch.cat([diag, offdiag, -offdiag])\n","\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return T\n","\n","# üìå Stabilit√§tstest f√ºr verschiedene Matrixgr√∂√üen\n","def stability_test():\n","    free_vram()\n","\n","    print(\"üåê Lade Zeta-Nullstellen...\")\n","    zeta_zeros = load_zeta_zeros()\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        free_vram()\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            print(f\"\\nüîç Hamilton-Operator H:\\n  - Shape: {H.shape}\\n  - dtype: {H.dtype}\\n  - Device: {H.device}\")\n","            print(f\"\\nüîç T-Operator:\\n  - Shape: {T.shape}\\n  - dtype: {T.dtype}\\n  - Device: {T.device}\")\n","\n","            # üîπ Kleinste Eigenwerte berechnen\n","            X = torch.randn(N, 500, device=device, dtype=torch.float32)\n","            eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JCF4EjK_Zvq","executionInfo":{"status":"ok","timestamp":1742196329871,"user_tz":-60,"elapsed":27835,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"905e889d-d436-4d49-fbaa-ebd3e3ea8958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üåê Lade Zeta-Nullstellen...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 42.47 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: indices and values must have same nnz, but got nnz from indices: 10000, nnz from values: 29998\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 42.47 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: indices and values must have same nnz, but got nnz from indices: 20000, nnz from values: 59998\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 42.47 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: indices and values must have same nnz, but got nnz from indices: 30000, nnz from values: 89998\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","import numpy as np\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1e9:.2f} GB | Reserviert: {torch.cuda.memory_reserved() / 1e9:.2f} GB | Frei: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    data = np.fromstring(response.text, sep=\"\\n\")\n","    return torch.tensor(data, dtype=torch.float32, device=device)\n","\n","# üìå Hamilton-Operator H\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = zeta_zeros.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    # ‚úÖ Korrekte Indizes f√ºr Sparse-Matrix\n","    row_idx = torch.cat([torch.arange(N, device=device), torch.arange(N-1, device=device), torch.arange(1, N, device=device)])\n","    col_idx = torch.cat([torch.arange(N, device=device), torch.arange(1, N, device=device), torch.arange(N-1, device=device)])\n","    values = torch.cat([diag, offdiag, offdiag])\n","\n","    indices = torch.stack([row_idx, col_idx])\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return H\n","\n","# üìå T-Operator T\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device, dtype=torch.float32)\n","    diag = beta_values.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    # ‚úÖ Korrekte Indizes f√ºr Sparse-Matrix\n","    row_idx = torch.cat([torch.arange(N, device=device), torch.arange(N-1, device=device), torch.arange(1, N, device=device)])\n","    col_idx = torch.cat([torch.arange(N, device=device), torch.arange(1, N, device=device), torch.arange(N-1, device=device)])\n","    values = torch.cat([diag, offdiag, -offdiag])\n","\n","    indices = torch.stack([row_idx, col_idx])\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return T\n","\n","# üìå Stabilit√§tstest\n","def stability_test():\n","    free_vram()\n","\n","    print(\"üåê Lade Zeta-Nullstellen...\")\n","    zeta_zeros = load_zeta_zeros()\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        free_vram()\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            print(f\"\\nüîç Hamilton-Operator H:\\n  - Shape: {H.shape}\\n  - dtype: {H.dtype}\\n  - Device: {H.device}\")\n","            print(f\"\\nüîç T-Operator:\\n  - Shape: {T.shape}\\n  - dtype: {T.dtype}\\n  - Device: {T.device}\")\n","\n","            # üîπ Kleinste Eigenwerte berechnen\n","            X = torch.randn(N, 500, device=device, dtype=torch.float32)\n","            eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wa32YgwP_813","executionInfo":{"status":"ok","timestamp":1742196463999,"user_tz":-60,"elapsed":20915,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"85b6c0ac-110e-4c2d-f7c5-3987b5b19a70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üåê Lade Zeta-Nullstellen...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 42.47 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=10000: Boolean value of Tensor with more than one value is ambiguous\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.03 GB | Reserviert: 0.04 GB | Frei: 42.44 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=20000: Boolean value of Tensor with more than one value is ambiguous\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.05 GB | Reserviert: 0.07 GB | Frei: 42.42 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=30000: Boolean value of Tensor with more than one value is ambiguous\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import gc\n","import requests\n","import numpy as np\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","def free_vram():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1e9:.2f} GB | Reserviert: {torch.cuda.memory_reserved() / 1e9:.2f} GB | Frei: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    data = np.fromstring(response.text, sep=\"\\n\")\n","    return torch.tensor(data, dtype=torch.float32, device=device)\n","\n","# üìå Hamilton-Operator H\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","    diag = zeta_zeros.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    # ‚úÖ Korrekte Indizes f√ºr Sparse-Matrix\n","    row_idx = torch.cat([torch.arange(N, device=device), torch.arange(N-1, device=device), torch.arange(1, N, device=device)])\n","    col_idx = torch.cat([torch.arange(N, device=device), torch.arange(1, N, device=device), torch.arange(N-1, device=device)])\n","    values = torch.cat([diag, offdiag, offdiag])\n","\n","    indices = torch.stack([row_idx, col_idx])\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return H\n","\n","# üìå T-Operator T\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device, dtype=torch.float32)\n","    diag = beta_values.clone().detach()\n","    offdiag = torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    # ‚úÖ Korrekte Indizes f√ºr Sparse-Matrix\n","    row_idx = torch.cat([torch.arange(N, device=device), torch.arange(N-1, device=device), torch.arange(1, N, device=device)])\n","    col_idx = torch.cat([torch.arange(N, device=device), torch.arange(1, N, device=device), torch.arange(N-1, device=device)])\n","    values = torch.cat([diag, offdiag, -offdiag])\n","\n","    indices = torch.stack([row_idx, col_idx])\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), dtype=torch.float32, device=device)\n","    return T\n","\n","# üìå Stabilit√§tstest\n","def stability_test():\n","    free_vram()\n","\n","    print(\"üåê Lade Zeta-Nullstellen...\")\n","    zeta_zeros = load_zeta_zeros()\n","    print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","    for N in [10_000, 20_000, 30_000]:\n","        free_vram()\n","        print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","        try:\n","            H = compute_H_operator(zeta_zeros[:N])\n","            T = compute_T_operator(N)\n","\n","            print(f\"\\nüîç Hamilton-Operator H:\\n  - Shape: {H.shape}\\n  - dtype: {H.dtype}\\n  - Device: {H.device}\")\n","            print(f\"\\nüîç T-Operator:\\n  - Shape: {T.shape}\\n  - dtype: {T.dtype}\\n  - Device: {T.device}\")\n","\n","            # üîπ Kleinste Eigenwerte berechnen\n","            X = torch.randn(N, 500, device=device, dtype=torch.float32)\n","\n","            # **Fix f√ºr den Fehler**\n","            if torch.any(H != 0):\n","                eigenvalues_H, _ = torch.lobpcg(H.to_dense(), X, largest=False)\n","                eigenvalues_T, _ = torch.lobpcg(T.to_dense(), X, largest=False)\n","\n","                delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","                print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","            else:\n","                print(f\"‚ö† Warnung: H ist null oder enth√§lt ung√ºltige Werte.\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","    print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")\n","\n","# üìå Hauptprogramm\n","if __name__ == \"__main__\":\n","    free_vram()\n","    stability_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSaguqeAAo8K","executionInfo":{"status":"ok","timestamp":1742196662415,"user_tz":-60,"elapsed":20646,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"eca88590-bb15-4c8b-b22b-e6d46210c44e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 42.47 GB\n","üåê Lade Zeta-Nullstellen...\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 42.47 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=10000: Could not run 'aten::ne.Scalar' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::ne.Scalar' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","Undefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","HIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","IPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","XPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","HPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","VE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","FPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Vulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Metal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","QuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:16106 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesBinaryOps.cpp:349 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.03 GB | Reserviert: 0.04 GB | Frei: 42.44 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=20000: Could not run 'aten::ne.Scalar' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::ne.Scalar' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","Undefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","HIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","IPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","XPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","HPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","VE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","FPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Vulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Metal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","QuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:16106 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesBinaryOps.cpp:349 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.05 GB | Reserviert: 0.07 GB | Frei: 42.42 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","\n","üîç T-Operator:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚ùå Fehler bei N=30000: Could not run 'aten::ne.Scalar' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::ne.Scalar' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n","\n","Undefined: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:30477 [kernel]\n","CUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:44731 [kernel]\n","HIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","IPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","XPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","HPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","VE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","PrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Meta: registered at /dev/null:241 [kernel]\n","FPGA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MAIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Vulkan: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","Metal: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:955 [kernel]\n","QuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","QuantizedMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","CustomRNGKeyId: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","MkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHIP: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMPS: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrIPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrXPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrHPU: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrVE: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMTIA: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse1: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse2: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrPrivateUse3: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","SparseCsrMeta: registered at /pytorch/build/aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21616 [default backend kernel]\n","BackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\n","Python: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\n","FuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:503 [backend fallback]\n","Functionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\n","Named: fallthrough registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:11 [kernel]\n","Conjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\n","Negative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\n","ZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\n","ADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:100 [backend fallback]\n","AutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHIP: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMPS: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradIPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradXPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradHPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradVE: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradLazy: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMTIA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradMeta: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","AutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_1.cpp:16915 [autograd kernel]\n","Tracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_1.cpp:16106 [kernel]\n","AutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:322 [backend fallback]\n","AutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:465 [backend fallback]\n","AutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\n","AutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\n","FuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/BatchRulesBinaryOps.cpp:349 [kernel]\n","BatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\n","FuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\n","Batched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079 [kernel]\n","VmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n","FuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\n","PythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\n","FuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:499 [backend fallback]\n","PreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\n","PythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n","\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","# üìå GPU oder CPU w√§hlen\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üìå VRAM freigeben\n","torch.cuda.empty_cache()\n","print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1e9:.2f} GB | \"\n","      f\"Reserviert: {torch.cuda.memory_reserved() / 1e9:.2f} GB | \"\n","      f\"Frei: {torch.cuda.mem_get_info()[0] / 1e9:.2f} GB\")\n","\n","# üìå Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    data = np.loadtxt(url, max_rows=2001052)  # Lade 2 Mio. Nullstellen\n","    return torch.tensor(data[:2000000], dtype=torch.float32, device=device)\n","\n","zeta_zeros = load_zeta_zeros()\n","print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","# üìå Hamilton-Operator erstellen (Sparse-Matrix)\n","def compute_H_operator(N):\n","    diag = torch.tensor(zeta_zeros[:N], device=device).clone().detach()\n","    indices = torch.arange(N, device=device).repeat(2, 1)\n","    values = torch.cat([diag, torch.ones(N-1, device=device), torch.ones(N-1, device=device)])\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return H\n","\n","# üìå Tridiagonale T-Matrix erstellen\n","def compute_T_operator(N):\n","    diag = torch.arange(1, N+1, device=device, dtype=torch.float32)\n","    off_diag = -torch.ones(N-1, device=device, dtype=torch.float32)\n","    indices = torch.cat([torch.arange(N, device=device).repeat(2, 1),\n","                         torch.arange(N-1, device=device).repeat(2, 1) + 1], dim=1)\n","    values = torch.cat([diag, off_diag, off_diag])\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return T\n","\n","# üìå Stabilit√§tstest f√ºr verschiedene N-Werte\n","for N in [10000, 20000, 30000]:\n","    torch.cuda.empty_cache()\n","    print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","\n","    try:\n","        H = compute_H_operator(N)\n","        T = compute_T_operator(N)\n","\n","        print(f\"\\nüîç Hamilton-Operator H:\\n  - Shape: {H.shape}\\n  - dtype: {H.dtype}\\n  - Device: {H.device}\")\n","        print(f\"\\nüîç T-Operator:\\n  - Shape: {T.shape}\\n  - dtype: {T.dtype}\\n  - Device: {T.device}\")\n","\n","        # Sparse-Matrix-Check f√ºr CUDA\n","        if H._nnz() > 0 and T._nnz() > 0:\n","            H_dense = H.to_dense()\n","            T_dense = T.to_dense()\n","\n","            # Kleinste 500 Eigenwerte berechnen\n","            k = min(N // 3, 500)\n","            X = torch.randn(N, k, device=device, dtype=torch.float32)\n","            eigenvalues_H, _ = torch.lobpcg(H_dense, X, largest=False)\n","            eigenvalues_T, _ = torch.lobpcg(T_dense, X, largest=False)\n","\n","            # Spektrale Abweichung berechnen\n","            delta_lambda = torch.norm(eigenvalues_H - eigenvalues_T).item()\n","            print(f\"üîç Spektrale Abweichung zwischen H und T: {delta_lambda:.6f}\")\n","        else:\n","            print(f\"‚ö† Warnung: H oder T enthalten keine g√ºltigen Werte.\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Fehler bei N={N}: {str(e)}\")\n","\n","    torch.cuda.empty_cache()\n","    print(f\"üîÑ VRAM freigegeben! Jetzt genutzt: {torch.cuda.memory_allocated() / 1e9:.2f} GB | \"\n","          f\"Reserviert: {torch.cuda.memory_reserved() / 1e9:.2f} GB | \"\n","          f\"Frei: {torch.cuda.mem_get_info()[0] / 1e9:.2f} GB\")\n","\n","print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nr0MJL7TBcDc","executionInfo":{"status":"ok","timestamp":1742196858345,"user_tz":-60,"elapsed":16117,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"626dd136-4db8-40df-f771-4a122d1dab4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.00 GB | Reserviert: 0.00 GB | Frei: 41.95 GB\n","‚úÖ Erfolgreich 2000000 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","‚ùå Fehler bei N=10000: indices and values must have same nnz, but got nnz from indices: 10000, nnz from values: 29998\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 41.93 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","‚ùå Fehler bei N=20000: indices and values must have same nnz, but got nnz from indices: 20000, nnz from values: 59998\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 41.93 GB\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","‚ùå Fehler bei N=30000: indices and values must have same nnz, but got nnz from indices: 30000, nnz from values: 89998\n","üîÑ VRAM freigegeben! Jetzt genutzt: 0.01 GB | Reserviert: 0.02 GB | Frei: 41.93 GB\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-aa2b0ed122e8>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  diag = torch.tensor(zeta_zeros[:N], device=device).clone().detach()\n"]}]},{"cell_type":"code","source":["import torch\n","import requests\n","import numpy as np\n","\n","# üîß Ger√§t ausw√§hlen (GPU, falls verf√ºgbar)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"üîç Nutze Ger√§t: {device}\")\n","\n","# üåê Zeta-Nullstellen laden\n","def load_zeta_zeros():\n","    url = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6\"\n","    response = requests.get(url)\n","    data = response.text.splitlines()\n","    return torch.tensor([float(line.strip()) for line in data], dtype=torch.float32, device=device)\n","\n","zeta_zeros = load_zeta_zeros()\n","print(f\"‚úÖ Erfolgreich {len(zeta_zeros)} Nullstellen geladen!\")\n","\n","# üõ† H-Operator berechnen (Sparse-Tridiagonal)\n","def compute_H_operator(N):\n","    diag = zeta_zeros[:N].clone().detach().to(device)  # Sicherstellen, dass es auf der GPU ist\n","    indices = torch.arange(N, device=device).repeat(2, 1)\n","\n","    # Off-Diagonale f√ºr Tridiagonale Struktur\n","    off_diag_indices = torch.stack([torch.arange(N - 1, device=device), torch.arange(1, N, device=device)])\n","    indices = torch.cat([indices, off_diag_indices, off_diag_indices.flip(0)], dim=1)\n","\n","    values = torch.cat([diag, torch.ones(N - 1, device=device), torch.ones(N - 1, device=device)])\n","\n","    # Debugging\n","    print(f\"üîç H-Operator f√ºr N={N}: Indices={indices.shape}, Values={values.shape}\")\n","\n","    H = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return H\n","\n","# üõ† T-Operator berechnen (Tridiagonal)\n","def compute_T_operator(N):\n","    diag = torch.arange(1, N+1, device=device, dtype=torch.float32)\n","    off_diag = -torch.ones(N-1, device=device, dtype=torch.float32)\n","\n","    indices = torch.cat([\n","        torch.arange(N, device=device).repeat(2, 1),  # Diagonal\n","        torch.stack([torch.arange(N-1, device=device), torch.arange(1, N, device=device)]),  # Off-Diagonal\n","        torch.stack([torch.arange(1, N, device=device), torch.arange(N-1, device=device)])   # Spiegelung\n","    ], dim=1)\n","\n","    values = torch.cat([diag, off_diag, off_diag])\n","\n","    # Debugging\n","    print(f\"üîç T-Operator f√ºr N={N}: Indices={indices.shape}, Values={values.shape}\")\n","\n","    T = torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","    return T\n","\n","# üìå Stabilit√§tstest durchf√ºhren\n","def stability_test(N_list):\n","    for N in N_list:\n","        try:\n","            print(f\"\\nüß™ Teste Stabilit√§t f√ºr N = {N}...\")\n","            H = compute_H_operator(N)\n","            T = compute_T_operator(N)\n","\n","            # Debugging\n","            print(f\"üîç Hamilton-Operator H:\\n  - Shape: {H.shape}\\n  - dtype: {H.dtype}\\n  - Device: {H.device}\")\n","            print(f\"üîç T-Operator:\\n  - Shape: {T.shape}\\n  - dtype: {T.dtype}\\n  - Device: {T.device}\")\n","\n","            # Dummy-Test\n","            diff = torch.norm(H.to_dense() - T.to_dense())\n","            print(f\"‚úÖ Test bestanden f√ºr N={N}, Differenz: {diff:.4f}\")\n","\n","        except Exception as e:\n","            print(f\"‚ùå Fehler bei N={N}: {e}\")\n","\n","# üìå Tests starten\n","N_list = [10_000, 20_000, 30_000]  # Anpassbar\n","stability_test(N_list)\n","\n","print(\"\\n‚úÖ Stabilit√§tstest abgeschlossen!\")"],"metadata":{"id":"lp-pl7Kd_9RN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742197090408,"user_tz":-60,"elapsed":18998,"user":{"displayName":"Tim Freese","userId":"03034664546839987454"}},"outputId":"4fbc515c-2d70-47ff-e4a2-181eaf8e95b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Nutze Ger√§t: cuda\n","‚úÖ Erfolgreich 2001052 Nullstellen geladen!\n","\n","üß™ Teste Stabilit√§t f√ºr N = 10000...\n","üîç H-Operator f√ºr N=10000: Indices=torch.Size([2, 29998]), Values=torch.Size([29998])\n","üîç T-Operator f√ºr N=10000: Indices=torch.Size([2, 29998]), Values=torch.Size([29998])\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","üîç T-Operator:\n","  - Shape: torch.Size([10000, 10000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚úÖ Test bestanden f√ºr N=10000, Differenz: 37823.7930\n","\n","üß™ Teste Stabilit√§t f√ºr N = 20000...\n","üîç H-Operator f√ºr N=20000: Indices=torch.Size([2, 59998]), Values=torch.Size([59998])\n","üîç T-Operator f√ºr N=20000: Indices=torch.Size([2, 59998]), Values=torch.Size([59998])\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","üîç T-Operator:\n","  - Shape: torch.Size([20000, 20000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚úÖ Test bestanden f√ºr N=20000, Differenz: 118174.8281\n","\n","üß™ Teste Stabilit√§t f√ºr N = 30000...\n","üîç H-Operator f√ºr N=30000: Indices=torch.Size([2, 89998]), Values=torch.Size([89998])\n","üîç T-Operator f√ºr N=30000: Indices=torch.Size([2, 89998]), Values=torch.Size([89998])\n","üîç Hamilton-Operator H:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","üîç T-Operator:\n","  - Shape: torch.Size([30000, 30000])\n","  - dtype: torch.float32\n","  - Device: cuda:0\n","‚úÖ Test bestanden f√ºr N=30000, Differenz: 335701.2188\n","\n","‚úÖ Stabilit√§tstest abgeschlossen!\n"]}]},{"cell_type":"code","source":["# üìå Sparse H-Operator korrekt erstellen\n","def compute_H_operator(zeta_zeros):\n","    N = len(zeta_zeros)\n","\n","    diag_indices = torch.arange(N, device=device)\n","    offdiag_indices = torch.arange(N - 1, device=device)\n","\n","    indices = torch.cat([diag_indices.unsqueeze(0), diag_indices.unsqueeze(0)], dim=0)\n","    indices_off = torch.cat([offdiag_indices.unsqueeze(0), (offdiag_indices + 1).unsqueeze(0)], dim=0)\n","\n","    values = torch.cat([zeta_zeros, torch.ones(N - 1, device=device), torch.ones(N - 1, device=device)])\n","    indices = torch.cat([indices, indices_off, indices_off.flip(0)], dim=1)  # Flip f√ºr symmetrische F√ºllung\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)\n","\n","# üìå Sparse T-Operator korrekt erstellen\n","def compute_T_operator(N):\n","    beta_values = torch.linspace(1, N, N, device=device)\n","\n","    diag_indices = torch.arange(N, device=device)\n","    offdiag_indices = torch.arange(N - 1, device=device)\n","\n","    indices = torch.cat([diag_indices.unsqueeze(0), diag_indices.unsqueeze(0)], dim=0)\n","    indices_off = torch.cat([offdiag_indices.unsqueeze(0), (offdiag_indices + 1).unsqueeze(0)], dim=0)\n","\n","    values = torch.cat([beta_values, torch.ones(N - 1, device=device), -torch.ones(N - 1, device=device)])\n","    indices = torch.cat([indices, indices_off, indices_off.flip(0)], dim=1)  # Flip f√ºr symmetrische F√ºllung\n","\n","    return torch.sparse_coo_tensor(indices, values, (N, N), device=device)"],"metadata":{"id":"tL77cw_AjCtQ"},"execution_count":null,"outputs":[]}]}